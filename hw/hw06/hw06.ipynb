{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58504b26",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw06.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8c8ae6",
   "metadata": {},
   "source": [
    "# üé≤ Homework 6: Probability and Estimators\n",
    "## Due Date: Thursday, April 10th, 11:59 PM PDT\n",
    "\n",
    "**‚ÄºÔ∏è Note: There is also a written portion of this HW! Be sure to complete both this notebook and the written assignment.**\n",
    "\n",
    "You must submit this assignment to Gradescope by the on-time deadline, Thursday, April 10th, at 11:59 PM. Please read the syllabus for the Slip Day policy. No late submissions beyond what is outlined in the Slip Day policy will be accepted. **We strongly encourage you to submit your work to Gradescope several hours before the deadline.** This way, you will have ample time to reach out to staff for support if you encounter difficulties with submission. While course staff is happy to help guide you with submitting your assignment ahead of the deadline, we will not respond to last-minute requests for assistance (TAs need to sleep, after all!).\n",
    "\n",
    "This is part of a two-part assignment. After completing this part (\"Homework 6 Coding\"), also remember to complete the \"Homework 6 (Statistics)\" assignment, which will be about deriving the mathematical aspects of random variables and estimators to help you in upcoming statistics courses during your time at Berkeley.\n",
    "\n",
    "Please read the instructions carefully when submitting your work to Gradescope. \n",
    "\n",
    "\n",
    "## Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about the homework, we ask that you **write your solutions individually**. If you do discuss the assignments with others please **include their names** below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625d357f",
   "metadata": {},
   "source": [
    "**Collaborators**: *list collaborators here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c38c5ac",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this homework, we will explore a dataset of the 2022 U.S. News & World Report rankings for liberal arts colleges.\n",
    "The dataset in this HW is a simplified version of the [original data source](https://andyreiter.com/datasets/).\n",
    "\n",
    "While working on this notebook, you will gain experience with the following:\n",
    "* Bootstrap sampling,\n",
    "* The bias-variance tradeoff and decomposition, and\n",
    "* Multicollinearity in features.\n",
    "\n",
    "## Grading\n",
    "Grading is broken down into auto-graded answers and free responses. \n",
    "\n",
    "For auto-graded answers, the results of your code are compared to provided and/or hidden tests.\n",
    "\n",
    "For free response, readers will evaluate how well you answered the question and/or fulfilled the requirements of the question. \n",
    "\n",
    "### Score breakdown\n",
    "\n",
    "Question | Manual | Points\n",
    "--- |---| ---\n",
    "1a| No | 2\n",
    "1b| No | 3\n",
    "1c| Yes | 3\n",
    "1d| Yes | 2\n",
    "1e| Yes | 1\n",
    "2a| No | 3\n",
    "2b| Yes |3\n",
    "2c| Yes | 1\n",
    "3a| No | 2\n",
    "3b| No | 2\n",
    "3c| No | 2\n",
    "3d(i)| Yes | 1.5\n",
    "3d(ii)| Yes | 1.5\n",
    "4a| No | 2\n",
    "4b| Yes | 2\n",
    "Total | 8 | 31\n",
    "\n",
    "If you run into any technical issues, we highly recommend checking out the [Data 100 Debugging Guide](https://ds100.org/debugging-guide/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3597dd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to set up your notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.precision', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ae55c9",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## üìà Question 1: Exploratory Data Analysis\n",
    "\n",
    "Let's perform some initial EDA to identify trends and patterns in the college ranking dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d399f586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to load the data; no further action is needed.\n",
    "college_data = pd.read_csv('data/2022_college_rankings.csv')\n",
    "college_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5130f947",
   "metadata": {},
   "source": [
    "The granularity of the dataset is an individual **college**; each row corresponds to metrics, ratings, and features of one college in the U.S.\n",
    "\n",
    "Here are the columns in the dataset:\n",
    "* `Institution`: The name of the college\n",
    "* `Type`: Whether the college is `'private'` or `'public'`\n",
    "* `Overall Score (0-100)`: The score computed by U.S. News & World Report to generate the ranking. **This is our outcome variable.**\n",
    "* The remaining columns contain features that are related to each college's overall score. \n",
    "\n",
    "We can use `college_data.info()` and `college_data.describe()` to see various statistics about the features of the provided college ranking data. Do any particular statistics stand out to you? Which might be useful when modeling?\n",
    "\n",
    "**Note:** This isn't a question, so it's not worth any points. This is just food for thought as you start to explore the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3789124",
   "metadata": {},
   "outputs": [],
   "source": [
    "college_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3487eb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "college_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f3bcf2-a56e-4d79-b126-7fbb5bdfbf2b",
   "metadata": {},
   "source": [
    "You may have observed that several features in the dataset are not shown when viewing with the `describe()` method. This is because those features are non-numeric. For example, some features are in the string format `\"XX%\"`.\n",
    "\n",
    "Before we can fit a linear model accounting for all features in the dataset, we have to convert all features to a numeric representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06776ec8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 1a\n",
    "\n",
    "Create a new `DataFrame` `cleaned_college_data` with the following changes:\n",
    "\n",
    "- For each column containing at least one missing value, add a new Boolean column that is `True` when the column value is missing, and `False` when the column value is not missing.\n",
    "    - For example, if there were a column containing the values `1, 2, NaN`, we would add a column containing the values `False, False, True`.\n",
    "    - If the original column name is `COLUMN`, the added column name should be `COLUMN_missing`. \n",
    "\n",
    "**Hint**: Use a `for` loop to iterate over the existing column names. You may find the `any()` function [(documentation)](https://docs.python.org/3/library/functions.html#any) useful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c903f696",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "cleaned_college_data = college_data.copy()\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe145c2b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2787a6f3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 1b\n",
    "\n",
    "Now, we will convert all non-numeric columns of `cleaned_college_data` into numbers. Additionally, we will create some new columns to encode additional information.\n",
    "\n",
    "To do so, complete the following tasks **in the order they are listed**:\n",
    "1. Consider the columns that contain the `'%'` symbol in any entry. Convert these columns from a string representation into the floating point number preceding `'%'`.\n",
    "    - For example, the string `\"96.4%\"` should be converted into floating point number `96.4`.\n",
    "2. Create a column called `\"Is Public\"` where the value is `1` if the row's college is public and `0` if the row's college is private.\n",
    "3. Create a column called `\"Is Private\"` where the value is `1` if the row's college is private and `0` if the row's college is public.\n",
    "4. Remove the `\"Type\"` and `\"Institution\"` columns.\n",
    "5. Replace all `NaN` values in the data with the mean of their respective column.\n",
    "\n",
    "**Hint**:\n",
    "- `pd.Series.fillna()` [(documentation)](https://pandas.pydata.org/docs/reference/api/pandas.Series.fillna.html) may come in handy.\n",
    "- You can select all string columns in a `DataFrame` object `df` with `df.select_dtypes(include=['object'])`[(documentation)](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.select_dtypes.html). Recall that strings are of the `object` type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389a3139",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "...\n",
    "cleaned_college_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f85ac0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c56e7e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 1c\n",
    "\n",
    "Linear models are sensitive to multicollinearity among the columns of the design matrix. So, let's determine the extent of multicollinearity in the college rankings dataset.\n",
    "\n",
    "In the following cell, we provide you with `arranged_cleaned_college_data`, which is a copy of `cleaned_college_data` containing just a subset of the columns arranged in a particular order. \n",
    "\n",
    "Create a visualization that shows the pairwise correlation between each combination of columns in `arranged_cleaned_college_data`. \n",
    "\n",
    "- For 2-D visualizations, consider the `sns.heatmap()` [documentation](https://seaborn.pydata.org/generated/seaborn.heatmap.html). \n",
    "\n",
    "- For full credit, title your plot, and set `annot=True`. This makes the plot easier to interpret.\n",
    "\n",
    "- You may find your plot easier to read with a different color scale. For example, try including `cmap=\"coolwarm\"` inside of `sns.heatmap()`.\n",
    "\n",
    "**Hint**: Your plot should show $10 \\times 10$ values corresponding to the [pairwise correlations](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html) of the selected columns in `arranged_cleaned_college_data`:\n",
    "```\n",
    "['Overall Score (0-100)', \n",
    "'Peer Assessment Score (1-5)', \n",
    "'Predicted 6yr graduation rate',\n",
    "'Actual 6yr graduation rate', \n",
    "'Graduation and retention rank', \n",
    "'Student Excellence rank',\n",
    "'Acceptance rate', \n",
    "'Financial resources rank', \n",
    "'Is Public', \n",
    "'Is Private']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a04ece9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Running this cell helps you get a subset of cleaned_college_data with the above columns\n",
    "arranged_cleaned_college_data = cleaned_college_data[\n",
    "    ['Overall Score (0-100)', \n",
    "     'Peer Assessment Score (1-5)', \n",
    "     'Predicted 6yr graduation rate',\n",
    "     'Actual 6yr graduation rate', \n",
    "     'Graduation and retention rank', \n",
    "     'Student Excellence rank',\n",
    "     'Acceptance rate', \n",
    "     'Financial resources rank', \n",
    "     'Is Public', \n",
    "     'Is Private']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56260b5b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Your output figure should look similar to the following example:\n",
    "\n",
    "<center><img src = \"images/heatmap.png\" width = \"600\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c7ca49",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a25b54",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 1d\n",
    "\n",
    "Do you notice any patterns in the plot from part (c)? What might explain these patterns? Comment and hypothesize on at least two patterns you notice.\n",
    "\n",
    "Here are some example questions to ponder:\n",
    "\n",
    "1. Why do some feature-pairs have correlations of $\\pm 1$? Is this a problem?\n",
    "2. What does the correlation between pairs of features (i.e., graduation-related statistics) look like? Is the magnitude of any of the correlations problemtatically close to 1?\n",
    "3. Are any features particularly strong predictors of the outcome? If so, why do you think this is the case?\n",
    "4. Do any features seem potentially redundant? In other words, do you suspect that any features provide similar information about the outcome as other features?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a673113c",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800eded6-448a-4837-99da-ce6174dc3ca9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "### Question 1e\n",
    "If we tried to fit a linear regression model with an intercept term using all features in `cleaned_college_data`, we might run into some problems when fitting our model.\n",
    "The Data 100 staff suggests that we perform the following operation to the `DataFrame` before fitting a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16ae980",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# You must run this cell to achieve pass the public tests for later questions.\n",
    "cleaned_college_data = cleaned_college_data.drop('Is Private', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade8c06b-550d-444e-a178-1698ebe206df",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Describe the reasoning behind this operation. What problem(s) do we avoid by removing the `Is Private` column from the model fitting process?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eecb722",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5079491b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## üèóÔ∏è Question 2: Constructing a Preliminary College Ranking Model\n",
    "\n",
    "In this question, you will fit a linear regression model to predict the U.S. News liberal arts college scores based on college metrics. Later, we will investigate the bias, variance, and observational noise of this model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584ef547",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 2a\n",
    "\n",
    "Train an `sklearn` OLS model that predicts each college's overall score using all of the other columns in `cleaned_college_data`. Include an intercept term in the model.\n",
    "\n",
    "Use `train_test_split()` [(documentation)](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to evaluate your model's RMSE on a held-out test set containing 33% of the college data; call the resulting splits `X_train`, `X_test`, `Y_train`, and `Y_test`.\n",
    "\n",
    "You can instantiate your linear regression model using `lm.LinearRegression` [(documentation)](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "\n",
    "**Note**: To pass the autograder, make sure to include `random_state=42` in your call to `train_test_split()` to generate a reproducible data split ([documentation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2525c32c",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Create train/test sets\n",
    "X = ...\n",
    "Y = ...\n",
    "X_train, X_test, Y_train, Y_test = ...\n",
    "\n",
    "# Fit the linear model and make predictions (you will need multiple lines)\n",
    "...\n",
    "\n",
    "\n",
    "\n",
    "# Compute RMSE on train and test sets\n",
    "train_rmse_cpc = ...\n",
    "test_rmse_cpc = ...\n",
    "\n",
    "train_rmse_cpc, test_rmse_cpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1140d2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7823ad",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 2b\n",
    "\n",
    "Let's visualize the model performance from part 2(a). Plot the following:\n",
    "1. The observed values vs. the predicted values on the test set.\n",
    "2. The residuals plot. Recall that for multiple linear regression, we plot the residuals against the predicted values.\n",
    "\n",
    "**In both plots, the predicted values should be on the x-axis.**\n",
    "\n",
    "**Note:**\n",
    "* For a full-credit solution, you should use `plt.subplot()` ([documentation](https://matplotlib.org/stable/gallery/subplots_axes_and_figures/subplots_demo.html)) so that you can view both visualizations side-by-side. \n",
    "    * The method `plt.subplot({# of rows}{# of cols}{index of plot})` sets the plottable area to the `index` of a `# rows` by `# cols` grid. \n",
    "    * For example, `plt.subplot(121)` sets the plottable area to the first index of a 1x2 plot grid. Calling `Matplotlib` and `Seaborn` functions will plot on the first index. When you're ready to start plotting on the second index, run `plt.subplot(122)`.\n",
    "* **Remember to add a guiding line to both plots where $\\hat{Y} = Y$, i.e., where the residual is 0**.\n",
    "    * `plt.plot()`[(documentation)](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html) and `plt.axhline()`[(documentation)](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.axhline.html) might be helpful here! \n",
    "* Make sure to add descriptive titles and axis labels.\n",
    "* To avoid distorted aspect ratios, ensure the limits of the x-axes for both plots are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce45870d",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))      # do not change this line\n",
    "plt.subplot(121)                # do not change this line\n",
    "# 1. plot observations vs. predictions\n",
    "...\n",
    "\n",
    "plt.subplot(122)               # do not change this line\n",
    "# 2. plot residual plot\n",
    "...\n",
    "\n",
    "plt.tight_layout()             # do not change this line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9185dd56",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 2c\n",
    "\n",
    "Describe what the plots in part (b) indicate about this linear model. In particular, are the predictions good, and do the residuals appear uncorrelated with the predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef14f0c",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad0bb3b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## ü§π Question 3: Confidence Intervals and Regression Coefficients\n",
    "\n",
    "We'll next analyze the statistical significance of coefficients in our linear model. Specifically, we will use bootstrapping to get $95\\%$ confidence intervals on the fitted parameters. Each step of bootstrapping corresponds to one part of this question:\n",
    "\n",
    "1. Question 3(a): Assume the sample is representative of the population from which it was drawn. To generate new, synthetic samples, we resample with replacement from the original sample. Generate `B` resamples.\n",
    "2. Question 3(b): Calculate a statistic for each of the `B` resamples. Possible statistics are the mean (Lab 9), correlation (Lab 9), coefficients of a linear model (Question 3 below), or any function of the sample data.\n",
    "3. Question 3(c): Construct a confidence interval by grabbing relevant percentiles of the `B` synthetic summary statistics. For example, for an 80% confidence interval, we grab the 10th and 90th percentiles.\n",
    "4. Question 3(d): Use the resulting confidence interval to make inferences about the population-level statistic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b26f95",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 3a\n",
    "\n",
    "Fill in the blanks below to implement the `bootstrap_sample()` function.\n",
    "\n",
    "Specification:\n",
    "- `bootstrap_sample()` returns a list of `B` bootstrap `DataFrame`s of the dataset `data`. \n",
    "- To generate a bootstrapped dataset from an actual dataset with $n$ rows, sample $n$ rows uniformly at random *with replacement* so that the bootstrapped `DataFrame` is the same size as the original `DataFrame`.\n",
    "\n",
    "**Hint**: You may find `df.sample()` helpful, see [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html). This is very similar to Lab 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542d7436",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def bootstrap_sample(data, B):\n",
    "    \"\"\"\n",
    "    Performs bootstrap sampling on data to obtain B samples of size n.\n",
    "    \n",
    "    Arguments:\n",
    "        data - Dataset contained as a pandas DataFrame \n",
    "        B - Number of randomly drawn samples\n",
    "    \n",
    "    Returns:\n",
    "        samples - List containing B pandas DataFrames of size n each\n",
    "                  corresponding to each sample  \n",
    "    \"\"\"\n",
    "    ...\n",
    "\n",
    "# Print out the first DataFrame only\n",
    "bootstrap_sample(cleaned_college_data, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d17d941",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770c545e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 3b\n",
    "\n",
    "Write a new function `generate_models()` with the following specifications:\n",
    "\n",
    "1. Generate 1000 bootstrapped samples from an inputted `DataFrame` called `original_df`. `bootstrap_sample()` will come in handy.\n",
    "2. For each of the 1000 bootstrapped samples, use `sklearn` to fit a linear regression model (with an intercept term) like we did in Question 2. `Overall Score (0-100)` is the response, and the rest of the columns are features. You should fit 1000 models in total. \n",
    "3. Store each of the 1000 trained models in a list called `models`. Return `models`.\n",
    "\n",
    "**Hints:**\n",
    "* You __should not__ create any validation or testing sets in this subpart; each model should fit to one entire bootstrapped `DataFrame`.\n",
    "* `LinearRegression` is an object type; to store a new model, you must create a new `LinearRegression` instance first!\n",
    "* Do not use `X` and `Y` as variable names while bootstrapping, as this will override the values stored in `q2a`.\n",
    "* When fitting each model, remember that your design matrix should be a 2D array or a `pandas` `DataFrame`, whereas the true labels should be a `Series`.\n",
    "\n",
    "**Note:** This question may take a few seconds to run due to the number of models being fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e1b10b",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "np.random.seed(42) # DO NOT REMOVE THIS LINE\n",
    "\n",
    "def generate_models(original_df):\n",
    "    datasets = ...\n",
    "    models = []\n",
    "    ...\n",
    "    # Datasets take up a lot of memory, so we should remove them!\n",
    "    del datasets\n",
    "    return ...\n",
    "\n",
    "\n",
    "full_feature_models = generate_models(cleaned_college_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6a311f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754713cc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 3c\n",
    "\n",
    "Complete the `confidence_interval` function below so that it generates a $95\\%$ confidence interval for each of our $p+1$ parameters in the original linear model, including the intercept term $\\theta_0$. \n",
    "\n",
    "Note: All of the helper code needed to extract coefficients from a list of trained models has been implemented for you.\n",
    "\n",
    "**Hint**: \n",
    "- For a refresher on confidence intervals, refer to this section in the [Data 8 textbook](https://inferentialthinking.com/chapters/13/3/Confidence_Intervals.html). \n",
    "- Pay close attention to how the arrays used below are formatted. What does each row represent? What does each column represent? To get the $i^{th}$ column from a 2D-array, you can use `2D_array[:, i]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40b3e47",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def extract_coefs(models, include_intercept = True):\n",
    "    \"\"\"\n",
    "    NOTE: This function has already been implemented. You do not need to modify this!\n",
    "    \n",
    "    Extracts coefficients of all the linear regression models in MODELS and returns\n",
    "    it as a NumPy array with each model's coefficients as one row.\n",
    "    \n",
    "    Arguments:\n",
    "        models - Contains k sklearn LinearRegression models, each with p + 1 coefficients.\n",
    "        include_intercept - Whether to include an intercept in returned coefficients.\n",
    "    \n",
    "    Returns:\n",
    "        coef_array - Coefficients of all k models, each with p + 1 coefficients (if intercept\n",
    "                     enabled, otherwise p). The returned object is k x (p + 1) NumPy array.\n",
    "    \"\"\"\n",
    "    coef_array = np.zeros(shape = (len(models), len(models[0].coef_) + 1))\n",
    "    for i, m in enumerate(models):\n",
    "        coef_array[i, 0] = m.intercept_\n",
    "        coef_array[i, 1:] = m.coef_\n",
    "    if include_intercept:\n",
    "        return coef_array \n",
    "    return coef_array[:, 1:]\n",
    "\n",
    "def confidence_interval(coefs):\n",
    "    \"\"\"\n",
    "    Calculates confidence intervals for each theta_i based on coefficients of \n",
    "    bootstrapped models. Returns output as a list of confidence intervals.\n",
    "    \n",
    "    Arguments:\n",
    "        coefs - Output of extract_coefs, a k x (p + 1) or k x p NumPy array containing\n",
    "                coefficients of bootstrapped models.\n",
    "    \n",
    "    Returns:\n",
    "        cis - Confidence intervals of each parameter theta_i in the form of a \n",
    "              list like this: [(0.5, 0.75), (0.2, 0.4), ...].\n",
    "    \"\"\"\n",
    "    cis = []\n",
    "    \n",
    "    # FILL IN CODE BELOW\n",
    "    for i in range(...):\n",
    "        theta_i_values = ...\n",
    "        theta_i_lower_ci, theta_i_upper_ci = np.percentile(...), np.percentile(...)\n",
    "        cis.append((theta_i_lower_ci, theta_i_upper_ci))\n",
    "    \n",
    "    return cis\n",
    "\n",
    "\n",
    "# Compute confidence intervals\n",
    "np.random.seed(42) # DO NOT REMOVE THIS LINE\n",
    "full_feature_models_coefs = extract_coefs(full_feature_models)\n",
    "full_feature_cis = confidence_interval(full_feature_models_coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2716f2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f472257c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 3d\n",
    "Using the code you have written above, we'll now compute the confidence intervals for the coefficients of two different linear models: Model A and Model B. \n",
    "\n",
    "- Recall that Model A uses all features, as defined in `full_feature_models`.\n",
    "\n",
    "- Model B uses a subset of features. The code below will help you fit Model B's coefficients and compute confidence intervals for them. Instances of Model B will be contained in `partial_feature_models`:\n",
    "\n",
    "**Note**: Depending on your implementation of `generate_models` and whether you ignore particular columns in that function, you may need to change the input of `generate_models`. You can use the sanity check below to test whether your `partial_feature_models` were built with the correct features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c908ce2-3933-4a79-95d0-9a9ad5a1d37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b_features = [\n",
    "     \"Peer Assessment Score (1-5)\",\n",
    "     \"Acceptance rate\"\n",
    "]\n",
    "partial_feature_models = generate_models(\n",
    "    cleaned_college_data[[\"Overall Score (0-100)\"] + model_b_features]\n",
    ")\n",
    "partial_feature_models_coefs = extract_coefs(partial_feature_models)\n",
    "partial_feature_cis = confidence_interval(partial_feature_models_coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75ab748-c546-4b3c-8069-ffe8b425c8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a sanity check, the following lines of code should all output True\n",
    "print(\"Coefficient shape is correct:\", partial_feature_models_coefs.shape == (1000, 3))\n",
    "print(\"Model input feature names are correct:\", (partial_feature_models[0].feature_names_in_ == model_b_features).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ec811d-1a97-4f83-92d4-51b9d530c79c",
   "metadata": {},
   "source": [
    "Here's a function that allows us to inspect the confidence interval of each model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d070c4-3067-4daf-9c34-f7f613a095d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confidence_intervals(models, cis):\n",
    "    display(Markdown('##### Confidence Intervals:'))\n",
    "    md_list = [\"|parameter|feature name|lower|upper|\",\n",
    "               \"----|----|----|----|\"]\n",
    "    coef_names = np.append(['Intercept'], models[0].feature_names_in_)\n",
    "    md_list += [r\"|$\\theta_{\" + str(i) + \"}\" + fr\"$|{f_name}|{np.round(lci, 3)}|{np.round(uci, 3)}|\" for i, ((lci, uci), f_name) in enumerate(zip(cis, coef_names))]\n",
    "    display(Markdown('\\n'.join(md_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3ed4f9-75cd-4f08-be75-dcdb3972b531",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### Question 3d(i)\n",
    "Let us first interpret **Model B**, the linear regression model that use a subset of features from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c6af13-738d-4d19-82a6-54c642eff7c0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "display(Markdown('#### Model B: Subset of Features'))\n",
    "print_confidence_intervals(partial_feature_models, partial_feature_cis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4886ad-4356-4ec5-8723-dc6a617492ba",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Are $\\theta_1$ and $\\theta_2$ significantly different than 0? How do you know? \n",
    "\n",
    "Does your answer imply that the relationship between `Overall Score (0-100)`, `Peer Assessment Score (1-5)`, and `Acceptance rate` are causal? Do you think the relationships are causal? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd75286",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ae286b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### Question 3d(ii)\n",
    "\n",
    "In what situation(s) would you prefer a more compact model with just key features, like Model B? On the other hand, in what situation(s) would you want to consider many features, like in Model A? Explain your answer to both of these questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f52ddd5",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d20bd06-2331-4537-8fe6-9bf92cc8cfcc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## ‚öñÔ∏è Question 4: Performing Bias-Variance Analysis\n",
    "\n",
    "This question will guide you through the concepts of model bias and model variance.\n",
    "\n",
    "Recall that the **model variance** on a particular data point ($\\vec{x_k}$) is the variance of the model predictions for $\\vec{x_k}$ across parallel universes of randomly sampled training datasets:\n",
    "\n",
    "$$\\text{model variance} = \\mathrm{Var}(\\hat{Y}(\\vec{x_k})) = \\mathrm{Var}(\\vec{x_k}^T\\hat{\\theta})$$\n",
    "\n",
    "> Note that $\\hat{Y}(\\vec{x_k})$ is an alternative way to write $\\hat{f}(\\vec{x_k})$ from lecture.\n",
    "\n",
    "To estimate the model variance, we can sample a particular data point $(\\vec{x_k}, y_k)$ and calculate the variance of the predictions for $(\\vec{x_k}, y_k)$ across parallel sampling universes, where each universe has a model fit to a randomly sampled training dataset. \n",
    "\n",
    "- As it turns out, you already have these fitted models stored in `models`!\n",
    "\n",
    "-  Note that the variance is computed across the different models, which have the same shared structure (i.e., the same input features and transformations). However, fitted parameter values will differ across models since the training data differs across models.\n",
    "\n",
    "Recall that **model risk** for a single point is the same as the mean squared error (MSE) of $\\vec{x_k}$ over our parallel universes of fitted models:\n",
    "\n",
    "$$\n",
    "\\text{model risk} = \\mathbb{E}\\left[\\left(y_k - \\hat{Y}(\\vec{x_k}) \\right)^2\\right] \\approx \\frac{1}{\\# \\text{ of bootstrap}}\\sum_{j=1}^{\\# \\text{ of bootstrap}} (y_k - \\hat{Y}_j(\\vec{x_k}))^2 = MSE(\\vec{x_k})\n",
    "$$\n",
    "\n",
    "where the subscript $j$ is used to index the different models. \n",
    "\n",
    "We can also compute the ratio of model variance to model risk:\n",
    "\n",
    "$$\n",
    "\\frac{\\text{model variance}}{\\text{model risk}}=\\frac{\\mathrm{Var}(\\hat{Y}(\\vec{x_k}))}{\\mathbb{E}\\left[\\left(y_k - \\hat{Y}(\\vec{x_k}) \\right)^2\\right]}\n",
    "$$\n",
    "\n",
    "This ratio provides a sense of how much of model risk can be attributed to model variance, relative to squared bias and irreducible error ($\\sigma^2$). You may find it helpful to recall the bias-variance decomposition from lecture:\n",
    "\n",
    "$$\n",
    "\\text{model risk} = \\sigma^2 + (\\text{model bias})^2 + \\text{model variance}\n",
    "$$\n",
    "\n",
    "where $\\sigma^2$ is the observational variance, or \"irreducible error\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4302f9fe",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 4a\n",
    "\n",
    "The function `simulate()` below takes in a single data point `xk`, `yk` and a list of models `models`.\n",
    "\n",
    "- `xk` is a list of feature values for a single data point. `yk` is the scalar outcome.\n",
    "\n",
    "`simulate()` function should return three quantities: the estimated model risk (`model_risk`), the estimated model variance (`model_var`), and the ratio of model variance to model risk (`ratio`).\n",
    "\n",
    "We have left one line blank for you to fill in:\n",
    "\n",
    "```model_risk, model_var, ratio = ...```\n",
    "\n",
    "Fill in the line correctly to complete the function `simulate`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c888da",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def simulate(xk, yk, models):\n",
    "    mystery_a = [model.predict([xk])[0] for model in models]\n",
    "    mystery_b = np.var(mystery_a)\n",
    "    mystery_c = np.mean((mystery_a - yk) ** 2)\n",
    "    mystery_d = mystery_b / mystery_c\n",
    "    model_risk, model_var, ratio = ...\n",
    "    return model_risk, model_var, ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04752d1b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2474933",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 4b\n",
    "\n",
    "Using the `simulate` function from above, we can compute the model risk, model variance, and variance-to-risk ratio of **Model B**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550a7146",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "x_last = X.iloc[X.shape[0] - 100]\n",
    "y_last = Y.iloc[X.shape[0] - 100]\n",
    "\n",
    "(\n",
    "    partial_feature_model_risk,\n",
    "    partial_feature_model_var,\n",
    "    partial_feature_model_ratio\n",
    ") = simulate(x_last[model_b_features], y_last, partial_feature_models)\n",
    "\n",
    "print('Model B risk:')\n",
    "print(partial_feature_model_risk)\n",
    "\n",
    "print('Model B variance:')\n",
    "print(partial_feature_model_var)\n",
    "\n",
    "print('Model B ratio:')\n",
    "print(partial_feature_model_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fa92f0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Comment on the variance-to-risk ratio for Model B (`partial_feature_ratio`).\n",
    "\n",
    "- Does the model variance appear to be the dominant term in the bias-variance decomposition? If not, what term(s) dominate the bias-variance decomposition?\n",
    "\n",
    "Then, given your conclusion above, describe what operation(s) you might perform to reduce the model risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae20dc8",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076c0b07",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "finish",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "tags": []
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>\n",
    "\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Congratulations! You have finished Homework 6!\n",
    "\n",
    "Here are some staff pets :) Can you find their names? There are two ways you can find it on JupyterLab.\n",
    "\n",
    "<img src=\"images/mango.jpg\" width=\"200px\"/> <img src=\"images/sage.jpg\" width=\"161px\" /> <img src=\"images/Pishi.jpg\" width=\"200px\" />\n",
    "\n",
    "\n",
    "### Course Content Feedback\n",
    "\n",
    "If you have any feedback about this assignment or about any of our other weekly, weekly assignments, lectures, or discussions, please fill out the [Course Content Feedback Form](https://docs.google.com/forms/d/e/1FAIpQLSenPfvkr0iHmkxD0v4bjEyo1iH2g0znEYe-OEkShrJikFkFfg/viewform?usp=sf_link). Your input is valuable in helping us improve the quality and relevance of our content to better meet your needs and expectations!\n",
    "\n",
    "### Submission Instructions\n",
    "\n",
    "Below, you will see a cell. Running this cell will automatically generate a zip file with your autograded answers. Once you submit this file to the HW 6 Coding assignment on Gradescope, Gradescope will automatically submit a PDF file with your written answers to the HW 6 Written assignment. If you run into any issues when running this cell, feel free to check this [section](https://ds100.org/debugging-guide/autograder_gradescope/autograder_gradescope.html#why-does-grader.exportrun_teststrue-fail-if-all-previous-tests-passed) in the Data 100 Debugging Guide.\n",
    "\n",
    "**Important**: Please check that your **plots/graphs and written responses** were generated and submitted correctly to the HW 6 Written Assignment.\n",
    "\n",
    "**You are responsible for ensuring your submission follows our requirements and that the PDF for HW 6 written answers was generated/submitted correctly. We will not be granting regrade requests nor extensions to submissions that don't follow instructions.** If you encounter any difficulties with submission, please don't hesitate to reach out to staff prior to the deadline. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716c86f2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcb8358",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d676572",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "otter": {
   "OK_FORMAT": true,
   "require_no_pdf_confirmation": true,
   "tests": {
    "q1a": {
     "name": "q1a",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> cleaned_college_data.shape == (167, 22)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> 'Pell gradrate_missing' in cleaned_college_data.columns\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1b": {
     "name": "q1b",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> bool(cleaned_college_data.dtypes.iloc[1:].apply(lambda t: pd.api.types.is_numeric_dtype(t)).all())\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> cleaned_college_data.shape == (167, 22)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2a": {
     "name": "q2a",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> bool(1.47 <= train_rmse_cpc <= 1.48)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(2.24 <= test_rmse_cpc <= 2.25)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3a": {
     "name": "q3a",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> bool(all([len(df_i) == len(cleaned_college_data) for df_i in bootstrap_sample(cleaned_college_data, 1)]))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(len(bootstrap_sample(cleaned_college_data, 3)) == 3)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3b": {
     "name": "q3b",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> bool(len(full_feature_models) == 1000)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(X.equals(cleaned_college_data.iloc[:, 1:]) and Y.equals(cleaned_college_data.iloc[:, 0]))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(all([isinstance(model, lm.LinearRegression) for model in full_feature_models]))\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3c": {
     "name": "q3c",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> bool(len(full_feature_cis) == 21 and all((len(ci) == 2 for ci in full_feature_cis)))\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4a": {
     "name": "q4a",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> x_test_ = X.iloc[-1]\n>>> y_test_ = Y.iloc[-1]\n>>> test_4a_model_risk, test_4a_model_var, test_4a_model_ratio = simulate(x_test_, y_test_, full_feature_models)\n>>> bool(test_4a_model_risk <= 0.5)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> x_test_ = X.iloc[-1]\n>>> y_test_ = Y.iloc[-1]\n>>> test_4a_model_risk, test_4a_model_var, test_4a_model_ratio = simulate(x_test_, y_test_, full_feature_models)\n>>> bool(test_4a_model_var <= 0.5)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> x_test_ = X.iloc[-1]\n>>> y_test_ = Y.iloc[-1]\n>>> test_4a_model_risk, test_4a_model_var, test_4a_model_ratio = simulate(x_test_, y_test_, full_feature_models)\n>>> bool(test_4a_model_ratio >= 0.7)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
