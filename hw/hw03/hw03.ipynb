{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw03.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üì∞ Homework 3: Text Analysis of New York Times Articles\n",
    "\n",
    "### Due Date: Thursday, February 20, 11:59 PM\n",
    "\n",
    "You must submit this assignment to Gradescope by the on-time deadline, **Thursday, February 20**, at 11:59 PM. Please read the syllabus for the Slip Day policy. No late submissions beyond what is outlined in the Slip Day policy will be accepted. **We strongly encourage you to submit your work to Gradescope several hours before the stated deadline.** This way, you will have ample time to reach out to staff for support if you encounter difficulties with submission. While course staff is happy to help guide you with submitting your assignment ahead of the deadline, we will not respond to last-minute requests for assistance.\n",
    "\n",
    "Please read the instructions carefully when submitting your work to Gradescope.\n",
    "\n",
    "## Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about the homework, we ask that you **write your solutions individually**. If you do discuss the assignments with others, please **include their names** below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collaborators**: _list collaborators here_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù This Assignment\n",
    "Welcome to Homework 3! In this assignment, we will analyze New York Times articles discussing trending topics from the past six years.\n",
    "\n",
    "You will gain experience with:\n",
    "\n",
    "- Cleaning and exploring a text-based dataset,\n",
    "- Manipulating data in `pandas` using `string` accessors,\n",
    "- Creating and interpreting visualizations with `seaborn`,\n",
    "- Writing and applying regular expressions (regex) with `pandas`, and\n",
    "- Performing sentiment analysis on text using the `DistilBERT` language model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to set up your notebook. \n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\")\n",
    "\n",
    "import re\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ds100_utils import *\n",
    "\n",
    "# Ensure that pandas shows at least 280 characters in columns, so we can see full articles.\n",
    "pd.set_option(\"max_colwidth\", 280)\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "sns.set()\n",
    "sns.set_context(\"talk\")\n",
    "sns.set_palette(\"colorblind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will use the [DistilBERT model](https://medium.com/huggingface/distilbert-8cf3380435b5), a Natural Language Processing (NLP) model designed to capture the context and meaning of words within sentences. While you are not expected to understand the intricate details of the model, we will utilize it to perform sentiment analysis on textual data. The necessary tools and the corresponding model are imported below.\n",
    "\n",
    "- **If you encounter any warnings, please ignore them. As long as the cell executes successfully, there should be no issues.**\n",
    "\n",
    "## ‚ö†Ô∏è IMPORTANT NOTE\n",
    "\n",
    "Due to limited computing resources on DataHub, the cell below **may take a significant amount of time to run** (potentially several minutes). This may also apply to other cells later in the assignment that load and use the NLP model.\n",
    "\n",
    "**Please be patient**, wait, and **avoid restarting the kernel or rerunning these cells** more than necessary. Doing so can slow down *your* notebook and impact *other students* on the same CPU cluster.\n",
    "\n",
    "Additionally, **DO NOT** open this assignment in multiple tabs or windows. This can cause your notebook to crash and affect DataHub's performance.\n",
    "\n",
    "Please be patient and seek assistance during Office Hours or on Ed if you encounter any issues!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Breakdown\n",
    "\n",
    " Question | Manual| Points\n",
    "--- |---| ---\n",
    "1a |No| 1\n",
    "1b |No| 1\n",
    "1c |No| 1\n",
    "2ai |No| 2\n",
    "2aii |No| 1\n",
    "2aiii |No| 2\n",
    "2bi |No| 1\n",
    "2bii |No| 1\n",
    "2biii |Yes| 1\n",
    "2c |No| 2\n",
    "2d |No| 2\n",
    "2e |No| 1\n",
    "2fi |Yes| 1\n",
    "2fii |Yes| 2\n",
    "3a |No| 1\n",
    "3bi |No| 1\n",
    "3bii |No| 1\n",
    "3c |Yes| 1\n",
    "3di |No| 1\n",
    "3dii |Yes| 1\n",
    "3e |Yes| 2\n",
    "**Total** | **6** | **27**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèéÔ∏è Before You Start\n",
    "\n",
    "For each question in the assignment, please write down your answer in the answer cell(s) right below the question.\n",
    "\n",
    "We understand that it is helpful to have extra cells breaking down the process towards reaching your final answer. If you happen to create new cells below your answer to run code, **NEVER** add cells between a question cell and the answer cell below it. It will cause errors when we run the autograder, and it will sometimes cause a failure to generate the PDF file.\n",
    "\n",
    "**Important note: The local autograder tests will not be comprehensive. You can pass the automated tests in your notebook but still fail tests on Gradescope after the grades are released.** Please be sure to check your results carefully.\n",
    "\n",
    "Finally, unless we state otherwise, **do not use for loops or list comprehensions**. The majority of this assignment can be done using built-in commands in `pandas` and `NumPy`.\n",
    "\n",
    "### Debugging Guide\n",
    "\n",
    "If you run into any technical issues, we highly recommend checking out the [Data 100 Debugging Guide](https://ds100.org/debugging-guide/). In this guide, you can find general questions about Datahub, Gradescope, and common `pandas` and RegEx errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 1: Importing the Data\n",
    "\n",
    "The data for this assignment is sourced from the [New York Times (NYT) Archive API](https://developer.nytimes.com/docs/archive-product/1/overview), which provides information about articles published in the past.\n",
    "\n",
    "The file `data/nyt_articles.txt` contains filtered data of specific NYT articles published between 2019 and 2024 (inclusive). Each article discusses trending topics, which we will specify shortly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 1a\n",
    "\n",
    "Let's examine the contents of the `data/nyt_articles.txt` file.\n",
    "\n",
    "Using the [`open()` function](https://docs.python.org/3/library/functions.html#open) and the [`read()` method](https://docs.python.org/3/tutorial/inputoutput.html#methods-of-file-objects) of a `python` file object, read **the first 330 characters** of the file `data/nyt_articles.txt` and store the result in the variable `q1a`. Then, print the result to inspect it.\n",
    "\n",
    "**CAUTION:** Viewing the contents of large files in a Jupyter Notebook can crash your browser. Be careful not to print the entire contents of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "...\n",
    "print(q1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "###  Question 1b\n",
    "\n",
    "Based on the printed output from `q1a`, what format is the data in?\n",
    "\n",
    "**A.** CSV<br/>\n",
    "**B.** JavaScript Object Notation (JSON)<br/>\n",
    "**C.** HTML<br/>\n",
    "**D.** Excel (XLSX)\n",
    "\n",
    "Answer in the following cell. Your answer should be a string, either `\"A\"`, `\"B\"`, `\"C\"`, or `\"D\"`, stored in the variable `q1b`.\n",
    "\n",
    "**CAUTION:** Viewing the contents of large files in a Jupyter Notebook can crash your browser. Be careful not to print the entire contents of the file, and do not use the file explorer to open data files directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "q1b = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "###  Question 1c\n",
    "`pandas` has built-in readers for many different file formats. To learn more about these, check out the documentation:\n",
    "\n",
    "- `pd.read_csv` [(docs)](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)\n",
    "- `pd.read_json` [(docs)](https://pandas.pydata.org/docs/reference/api/pandas.read_json.html)\n",
    "- `pd.read_html` [(docs)](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_html.html)\n",
    "- `pd.read_excel` [(docs)](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html)\n",
    "\n",
    "Load the file `data/nyt_articles.txt` as a `DataFrame`, and store it in the variable `news_df`.\n",
    "\n",
    "**Hint:** If your code is taking a while to run, you should review your answers to `q1a` and `q1b`; you may have used the incorrect data loading function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "...\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "##  Question 2: Topic Trends Over Time\n",
    "\n",
    "Now that we've loaded the NYT data, let's analyze trends in different topics. This will help us understand how various subjects have evolved over the years and identify any significant patterns or shifts in public interest.\n",
    "\n",
    "We will start by extracting date and time information from the articles and then proceed to analyze the frequency and context of specific topics mentioned in the articles.\n",
    "\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "###  Question 2a\n",
    "\n",
    "In this question, we will process the `pub_date` column of our dataset to canonicalize time-related data.\n",
    "This will help us investigate the trend of news articles across units of time like years, months, and seasons.\n",
    "\n",
    "####  Question 2a, Part i\n",
    "\n",
    "Create a new `DataFrame` called `dates` that contains:\n",
    "1. The same index as `news_df`\n",
    "2. Three columns: `Month`, `Year`, and `Minute`, which contain the month, year, and minute, respectively, that each article was published.\n",
    "\n",
    "Additionally, convert all numerical values (`Month`, `Year`, `Minute`) to type `int`.\n",
    "\n",
    "**Note:** For this problem, you are not permitted to use methods from the `Series.dt` accessor.\n",
    "\n",
    "**Hint 1:** Use the `Series.str.extract` function ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.extract.html)).\n",
    "\n",
    "**Hint 2:** Use raw strings and capture groups. You may find it helpful to copy the example date and time entries above into [regex101.com](https://regex101.com/) to experiment with regular expressions.\n",
    "\n",
    "**Hint 3:** It might be helpful to break this up into a couple of steps (e.g., first extract date values and then extract time values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2ai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "####  Question 2a, Part ii\n",
    "\n",
    "We aim to analyze topic trends over time by merging news article data with corresponding date and time data. \n",
    "\n",
    "Use the `pd.DataFrame.merge` [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html) to merge the `dates` `DataFrame` with the `news_df` `DataFrame`. Ensure that `news_df` is the left `DataFrame` and `dates` is the right `DataFrame` in the merge operation.\n",
    "\n",
    "Assign the merged `DataFrame` to a variable named `news_df_dates`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "news_df_dates = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2aii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 2a, Part iii\n",
    "\n",
    "Add a column to `news_df_dates` called `Quarter` that contains the [fiscal quarter](https://www.investopedia.com/terms/q/quarter.asp#:~:text=The%20standard%20calendar%20quarters%20that,August%2C%20and%20September%20(Q3)) each news article was published.\n",
    "\n",
    "Each value of `Quarter` should be in the format `\"<Year>Q<Quarter Number>\"`.\n",
    "\n",
    "For example:\n",
    "- A news article published in May 2021 will have its `Quarter` value as `\"2021Q2\"`.\n",
    "- A news article published in October 2023 will have its `Quarter` value as `\"2023Q4\"`.\n",
    "\n",
    "Do not hardcode the conversion from month to quarter (e.g., using the dictionary `{1: 'Q1', 2: 'Q1', ..., 12: 'Q4'}`). Instead, perform a mathematical operation to convert the month to quarter.\n",
    "\n",
    "**Hint:** Adding two `Series` of strings (e.g., `ser_1 + ser_2`) performs an element-wise concatenation of their elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2aiii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "###  Question 2b\n",
    "\n",
    "In this question, we will answer some EDA questions about `news_df_dates`.\n",
    "\n",
    "####  Question 2b, Part i\n",
    "In `news_df_dates`, suppose we create a new column `num_google_mentions` that records the number of times the word `\"google\"` is mentioned in each news article. What type of variable is `num_google_mentions`?\n",
    "\n",
    "**A.** Quantitative variable<br/>\n",
    "**B.** Qualitative Ordinal variable<br/>\n",
    "**C.** Qualitative Nominal variable\n",
    "\n",
    "Answer in the following cell. Your answer should be a string, either `\"A\"`, `\"B\"`, or `\"C\"`, stored in the variable `q2bi`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "q2bi = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2bi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "####  Question 2b, Part ii\n",
    "Which of the following options best describes the granularity of `news_df_dates`? \n",
    "\n",
    "Each row in `news_df_dates` uniquely describes:\n",
    "\n",
    "**A.** A calendar date. <br/>\n",
    "**B.** An hour of a calendar date. <br/>\n",
    "**C.** A news article.\n",
    "\n",
    "Answer in the following cell. Your answer should be a string, either `\"A\"`, `\"B\"`, or `\"C\"`, stored in the variable `q2bii`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "q2bii = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2bii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "####  Question 2b, Part iii\n",
    "\n",
    "Suppose we wanted to investigate trends in how often the word `\"AI\"` is mentioned in NYT articles since the 1980s.\n",
    "\n",
    "Is `news_df` a suitable dataset for this investigation? Explain your reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "###  Question 2c\n",
    "\n",
    "Some news articles include quotes in their lead paragraph (i.e., first paragraph) to grab the reader's attention and provide additional context. For the purposes of this question, a quote is defined as a sequence of characters starting with the character `\"` and ending with a period (`.`), question mark (`?`), or exclamation point (`!`), followed by a closing `\"`. For example:\n",
    "- `\"The mitochondria is the powerhouse of the cell!\"`\n",
    "- `\"Did DATA C100 course staff host a social event with staff from DATA C8?\"`\n",
    "- `\"R is great.\" A TA said, \"but have you tried using Python?\"`\n",
    "\n",
    "If we follow the definition above, the following text snippet contains two quotes:\n",
    "- `The TA asked, \"What's the purpose of regular expressions?\" The student thought for a moment and then replied, \"Regex are used to identify patterns in text.\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "\n",
    "\n",
    "Brandon wants to extract individual quotes from paragraphs using the definition of a quote given above.\n",
    "Brandon proposes the regex pattern `r'\\\".*[\\.\\?\\!]\\\"'`. Unfortunately, Brandon's pattern identifies only one quote in the test string below instead of two.\n",
    "\n",
    "Modify Brandon's regex pattern so that it correctly matches the two quotes individually. Store your new pattern in the variable `modified_pattern`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "test_string = '\"How are your classes?\" the student asked. \"Super challenging! But a lot of fun!\" said their roommate.'\n",
    "\n",
    "print(\"Test string:\", test_string)\n",
    "print(\"Original pattern identifies:\", re.findall(r'\\\".*[\\.\\?\\!]\\\"', test_string))\n",
    "\n",
    "modified_pattern = ...\n",
    "print(\"Modified pattern identifies:\", re.findall(modified_pattern, test_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "###  Question 2d\n",
    "\n",
    "Next, we will investigate popularity trends of the following four topics: [New Year](https://en.wikipedia.org/wiki/New_Year), [Wordle](https://www.nytimes.com/games/wordle/index.html), [Zoom](https://www.zoom.com/), and [GPT models](https://en.wikipedia.org/wiki/Generative_pre-trained_transformer).\n",
    "\n",
    "For each topic, add an integer column to `news_df_dates` indicating the number of times the topic is mentioned in the `lead_paragraph` (i.e., first paragraph) of each article. \n",
    "\n",
    "- The columns should be named `\"New Year\"`,  `\"Zoom\"`, `\"Wordle\"`, and `\"GPT Model\"`.\n",
    "\n",
    "- You may use a `for` loop to iterate over a list of the four topics.\n",
    "\n",
    "Here are the definitions of a single \"mention\" of each topic:\n",
    "- New Year: An appearance of `\"New Year\"` or `\"New Years\"`, surrounded by non-word characters, in the lead paragraph of the article. For example, `\"Happy New Year!\"` is a match.\n",
    "- Wordle: `\"Wordle\"`, surrounded by non-word characters. For example, `\"Wordless\"` would not match.\n",
    "- Zoom: `\"Zoom\"`, surrounded by non-word characters. For example, `\"Zoomer\"` would not match.\n",
    "- GPT Model: either (1) a consecutive sequence of alphabetical characters, followed by an optional dash (`-`), then `GPT`; or (2) `GPT`, then a dash (`-`), then a numeric digit, then an optional alphabetical character.\n",
    "    - For example, these words match: `\"ChatGPT\"`, `\"CHAT-GPT\"`, `\"GPT-3\"`, `\"GPT-4o\"`.\n",
    "    - However, these words do not match: `\"chatgpt\"`, `\"chatgpt-4o\"`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "news_df_dates.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "###  Question 2e\n",
    "\n",
    "Create a new `DataFrame` called `topic_mentions` with the following characteristics:\n",
    "\n",
    "- There should be one column for each topic (`\"New Year\"`,  `\"Zoom\"`, `\"Wordle\"`, and `\"GPT Model\"`).\n",
    "\n",
    "- The index should be `Quarter`.\n",
    "\n",
    "- The values are the number of articles that mentioned each topic in each quarter. \n",
    "\n",
    "**Hint**: Define a helper function `num_mentioned(ser)`, which takes a `Series` object `ser` and returns the number of entries in `ser` that are larger than `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "topics = [\"New Year\", \"Wordle\", \"Zoom\", \"GPT Model\"]\n",
    "\n",
    "...\n",
    "\n",
    "# Year 2023 records\n",
    "topic_mentions[16:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "### Question 2f\n",
    "\n",
    "Let's visualize the article counts for each topic by quarter from 2019 to 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 2f, Part i\n",
    "\n",
    "Using `sns.lineplot` ([documentation](https://seaborn.pydata.org/generated/seaborn.lineplot.html)) and `topic_mentions`, visualize the topic trends across quarters. Your plot should look like this:\n",
    "\n",
    "<center>\n",
    "    <img src=\"./images/topic_mentions.png\" width=\"750\" align=\"left\">\n",
    "</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5)) # DO NOT MODIFY\n",
    "\n",
    "for topic in topics:\n",
    "    ...\n",
    "\n",
    "# DO NOT MODIFY THE CODE BELOW\n",
    "# If your solution above is correct, running this cell should produce the plot above.\n",
    "plt.xticks(rotation=60)\n",
    "plt.yticks()\n",
    "plt.ylabel(\"Number of Articles\")\n",
    "plt.xlabel(\"Quarter\")\n",
    "plt.title(\"Number of Articles Released (2019-2024)\")\n",
    "plt.gcf().set_facecolor('white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "####  Question 2f, Part ii\n",
    "\n",
    "For each of the four topics, identify one interesting pattern in the visualization and provide a tentative explanation of why you think the pattern exists.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "    <img src = \"images/topic_mentions.png\" width = \"750\" align=\"left\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "##  Question 3: Sentiment Analysis\n",
    "\n",
    "**Sentiment analysis** involves using an NLP model to classify the emotional tone of text. For example, \"You're great!\" has a positive sentiment, while \"I feel horrible\" has a negative sentiment.\n",
    "\n",
    "In this section, we will explore temporal changes in the **sentiment** of NYT articles that mention each topic.\n",
    "\n",
    "> The sentiment values in this section were computed using a fine-tuned version of the **DistilBERT** model ([GitHub](https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation), [original paper](https://arxiv.org/abs/1910.01108)).\n",
    ">\n",
    "> DistilBERT is a neural network-based language model similar to ChatGPT. These models are not covered in Data 100, and we don't expect you to know how they work. If you're interested in learning more, consider taking `CS182: Neural Networks` or `Data 102: Data, Inference, and Decisions`.\n",
    ">\n",
    "> The [HuggingFace library](https://huggingface.co/) was used to build the sentiment analysis pipeline and load the model. [Here](https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english) is the **model card** of the `DistilBERT` model we used. The model card contains general information about the model, such as training arguments and training data. Again, you don't need to know these details for Data 100!\n",
    "\n",
    "Run the following three cells to set up the sentiment analysis pipeline and see examples of how we can get the sentiment for different strings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "model_checkpoint = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\", model=model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Get the sentiment of a given string\n",
    "sentiment_1 = sentiment_analysis(\"I have two dogs.\")\n",
    "print(\"Example 1: \" + str(sentiment_1))\n",
    "\n",
    "sentiment_2 = sentiment_analysis(\"I do not have dogs.\")\n",
    "print(\"Example 2: \" + str(sentiment_2))\n",
    "\n",
    "sentiment_3 = sentiment_analysis(\"Fortunately, I do not have dogs to worry about.\")\n",
    "print(\"Example 3: \" + str(sentiment_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "As you can see, the model can determine the sentiment of phrases/sentences (not just words). The model measures the phrase's **polarity**, indicating how strongly negative or positive it is on a scale of 0 to 1.\n",
    "\n",
    "**Note:** The output is a list, and each list element is a dictionary with two keys (label and score). Note that we could have gotten the sentiments of the two sentences by putting them in a list (batch) and then running the pipeline once (see the code below).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "sentiments = sentiment_analysis([\"I have two dogs.\", \"I do not have dogs.\"])\n",
    "print(sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "###  Question 3a\n",
    "\n",
    "Try it out yourself! The sentences we provided in the previous example have pretty high polarity scores. Let's see how the model behaves with more ambiguous sentences.\n",
    "\n",
    "Write a sentence `less_polar_sentence` that has a polarity score of less than 0.8. This may take some trial and error. Let this be an opportunity to think about whether the model works as you'd expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "less_polar_sentence = ...\n",
    "results = sentiment_analysis(less_polar_sentence)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "###  Question 3b\n",
    "\n",
    "As a first step, let's obtain the sentiment of the NYT articles that mention these **three** topics: `Zoom`, `New Year`, and `GPT`. \n",
    "\n",
    "**Note:** We will not analyze the sentiment of articles that mention `Wordle`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "####  Question 3b, Part i\n",
    "\n",
    "Create a `DataFrame` called `news_df_filtered` that contains all articles from `news_df_dates` that mention `Zoom`, `New Year`, or `GPT`, but do not mention `Wordle`. Use the same definitions from Question 2c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "news_df_filtered = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3bi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "####  Question 3b, Part ii\n",
    "\n",
    "Having all 1000+ students in Data 100 run the `DistilBERT` model for all articles is too computationally intensive for DataHub. So, we have done this part for you and saved the article sentiment scores in  `nyt_sentiments.csv`:\n",
    "\n",
    "1. Load the file `data/nyt_sentiments.csv` as a `DataFrame` called `sentiment`. \n",
    "2. Set the index of `sentiment` as the `web_url` of each article, which uniquely defines each article.\n",
    "\n",
    "Note that the model outputs both a label and a score. After importing the data, we recommend taking a look at its structure before attempting the next part.\n",
    "\n",
    "For each article, `sentiment` provides an outputted `label` and 0 to 1 sentiment `score`. Scores closer to 1 have a stronger sentiment, while scores closer to 0 are more neutral. We can more efficiently communicate the information in these two columns with a single new column. \n",
    "\n",
    "3. Add a new column called `article_sentiment` to `sentiment` that provides the existing score if the label is \"POSITIVE\", and negates the existing score if the label is \"NEGATIVE\". For example, a score of `0.6` with a label `POSITIVE` would have the value `0.6` in `article_sentiment`, while a score of `0.6` with a label `NEGATIVE` would have the value `-0.6` in `article_sentiment`.\n",
    "\n",
    "4. Merge `news_df` with `sentiment` using the `web_url` column, making sure that `news_df` is the left `DataFrame` while `sentiment` is the right `DataFrame`. The merged `DataFrame` should be called `news_df_sentiment`.\n",
    "\n",
    "5. Finally, drop the original `label` and `score` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3bii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "###  Question 3c\n",
    "\n",
    "Let's now visualize the distribution of article sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Using `seaborn`, we created a histogram to visualize the distribution of `article_sentiment`. Run the cell below to display the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "sns.histplot(data=news_df_sentiment, x='article_sentiment')\n",
    "plt.xlabel('Sentiment of Leading Paragraphs')\n",
    "plt.title('Histogram of Leading Paragraph Sentiment')\n",
    "plt.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Are you at all surprised by the distribution of sentiment in the graph above? Describe what you notice about the graph and how it relates to what you learned in part **3a**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "###  Question 3d\n",
    "\n",
    "Let's audit our data to better understand how well the sentiment analysis model works with our specific dataset. It's good practice to compare our assumptions to model outputs.\n",
    "\n",
    "####  Question 3d, Part i\n",
    "\n",
    "Assign `top_positive` and `top_negative` to `DataFrame`s containing the five articles with the highest `article_sentiment` values and the five lowest `article_sentiment` values, respectively. The `DataFrame`s should have the columns `lead_paragraph` and `article_sentiment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "top_positive = ...\n",
    "top_negative = ...\n",
    "\n",
    "display(top_positive, top_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3di\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "####  Question 3d, Part ii\n",
    "\n",
    "Do you agree with the current sentiment-based ordering of news articles, or would you rearrange the ordering? Do you feel that the DistilBERT model is a good model for our task of analyzing sentiment in news articles?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continued Visualizing\n",
    "Let's continue to visualize the `news_df_sentiment` data. The cell below adds a new datetime column `date` to `news_df_sentiment`. The datetime format will make visualization easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the columns into a single date string in 'YYYY-MM-DD' format\n",
    "news_df_sentiment['date_str'] = (\n",
    "    news_df_sentiment['Year'].astype(str)\n",
    "    + '-' + news_df_sentiment['Month'].astype(str)\n",
    "    + '-' + news_df_sentiment['pub_date'].str[8:10]\n",
    ")\n",
    "\n",
    "# Convert the combined string to a datetime object using pd.to_datetime()\n",
    "news_df_sentiment['date'] = pd.to_datetime(news_df_sentiment['date_str'], format='%Y-%m-%d', errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we visualize the change in sentiment in the topic `Zoom` over time, using `sns.lineplot` to plot `date` on the x-axis and `article_sentiment` on the y-axis.\n",
    "\n",
    "**Note**: If the following plot is empty, please rerun from all cells starting from Part 3b where `news_df_sentiment` was initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "sns.lineplot(data=news_df_sentiment[news_df_sentiment[\"Zoom\"] > 0], x='date', y='article_sentiment')\n",
    "plt.xticks(rotation=70);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This plot is not very pretty!** This isn't because of any errors on your part. Instead, we need to use a different visualization method to understand our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "###  Question 3e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Let's visualize our data more effectively. We will still use `sns.lineplot`, but instead of plotting every observation, we will first aggregate our data, and then plot the aggregated values.\n",
    "\n",
    "We will also compare sentiment scores across three topics: `New Year`, `Zoom`, and `GPT`.\n",
    "\n",
    "We will use the `DataFrame` `news_df_sentiment` in this question.\n",
    "\n",
    "1. For each topic, generate a `DataFrame` that shows the average article sentiment for each quarter. In each `DataFrame`, be sure to include a column called `Topic` that has the same string value in every row (either `New Year`, `Zoom` or `GPT`).\n",
    "2. Concatenate the `DataFrame`s obtained from step (1) using `pd.concat` ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.concat.html)). Assign this to `all_topic_qtr_avg_sentiments`.\n",
    "3. Finally, we have provided the code to plot each topic's average article sentiment in each quarter using `all_topic_qrt_avg_sentiments`.\n",
    "\n",
    "Your graph should have a similar title, axis labels, markers, and x-axis tick label ordering as the one below.\n",
    "\n",
    "<img src = \"images/sentiment_graph.png\" width = \"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "dfs_per_topic = []\n",
    "\n",
    "for topic in topics:\n",
    "    df_of_current_topic = ...\n",
    "    df_of_current_topic[\"Topic\"] = ...\n",
    "    ...\n",
    "\n",
    "all_topic_qtr_avg_sentiments = ...\n",
    "sns.lineplot(data=all_topic_qtr_avg_sentiments, x=\"Quarter\", y=\"article_sentiment\", hue=\"Topic\")\n",
    "\n",
    "plt.title('Avg. Sentiment per Topic Across Quarters')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Lead Paragraph Sentiment')\n",
    "\n",
    "# If the above are implemented correctly, running this cell should produce the graph shown above.\n",
    "plt.axhline(0, color='black')\n",
    "plt.xticks(rotation=65);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "\n",
    "In this homework, we used a language model to evaluate the sentiment of news articles and quantify text data (qualitative data) so that we could perform data analysis on a large set of journalism data. Though we used the [HuggingFace DistilBERT](https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english) model, there are thousands of language models available for use, and with rapid innovations in the NLP research space, there are new models frequently being created. In fact, we were using a different model for this homework one year ago, which reflects how quickly the NLP field progresses. \n",
    "\n",
    "Different models evaluate sentiment differently. You may have noticed that the DistilBERT model struggles with evaluating neutral sentences and often gives sentences a high polarity score. When evaluating which models to use in your projects, it's useful to test them on small inputs of data to see how they perform, like we did by testing out various sentences! Different models may perform differently (often due to how the model was trained and created), so it's important to understand these differences when deciding what model to use for your data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Levi says congratulations! You have finished Homework 3!\n",
    "\n",
    "<img src = \"images/IMG_6497.jpg\" width = \"200\">\n",
    "\n",
    "### Course Content Feedback\n",
    "\n",
    "If you have any feedback about this assignment or about any of our other weekly, weekly assignments, lectures, or discussions, please fill out the [Course Content Feedback Form](https://forms.gle/5SxnFnCPZgCr2koeA). Your input is valuable in helping us improve the quality and relevance of our content to better meet your needs and expectations!\n",
    "\n",
    "### Submission Instructions\n",
    "\n",
    "Below, you will see a cell. Running this cell will automatically generate a zip file with your autograded answers. Once you submit this file to the HW 3 Coding assignment on Gradescope, Gradescope will automatically submit a PDF file with your written answers to the HW 3 Written assignment. If you run into any issues when running this cell, feel free to check this [section](https://ds100.org/debugging-guide/autograder_gradescope/autograder_gradescope.html#why-does-grader.exportrun_teststrue-fail-if-all-previous-tests-passed) in the Data 100 Debugging Guide.\n",
    "\n",
    "**Important**: Please check that your written responses were generated and submitted correctly to the HW 3 Written Assignment.\n",
    "\n",
    "**You are responsible for ensuring your submission follows our requirements and that the PDF for HW 3 written answers was generated/submitted correctly. We will not be granting regrade requests nor extensions to submissions that don't follow instructions.** If you encounter any difficulties with submission, please don't hesitate to reach out to staff prior to the deadline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "otter": {
   "OK_FORMAT": true,
   "require_no_pdf_confirmation": true,
   "tests": {
    "q1a": {
     "name": "q1a",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> q1a.startswith('[{\"web_url\":\"https:\\\\/\\\\/www.nytimes.com\\\\/2019\\\\/01\\\\/01\\\\/us\\\\/politics\\\\/elizabeth-warren-president.html\"')\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1b": {
     "name": "q1b",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> q1b.upper() in ['A', 'B', 'C', 'D']\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1c": {
     "name": "q1c",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> set(['web_url', 'pub_date', 'lead_paragraph']) == set(news_df.columns)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> news_df.shape == (1885, 3)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> news_df.loc[50, 'web_url'] == 'https://www.nytimes.com/2019/07/30/arts/television/four-weddings-and-a-funeral-review-hulu.html'\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> news_df.loc[203, 'pub_date'] == '2020-06-02T19:31:01+0000'\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> news_df.loc[919, 'lead_paragraph'] == 'At the Chelsea Piers outdoor golf club, on a recent unseasonably warm Monday afternoon, 55 people were playing golf by 3:45, and a handful were sipping beers. At CutLoose hair salon, in Brooklyn, N.Y., the stylists now watch their clients take Zoom meetings from the salon chairs. And at Skyway Golf Course, in Jersey City, N.J., Steve Mills, a general manager, has noticed that weekday afternoons are jammed with a new group of golfers.'\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2ai": {
     "name": "q2ai",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> {'Month', 'Year', 'Minute'} == set(dates.columns).intersection({'Month', 'Year', 'Minute'})\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> dates['Year'].dtype == int\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> dates['Month'].dtype == int\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> dates['Minute'].dtype == int\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2aii": {
     "name": "q2aii",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> set(news_df_dates.columns) == {'Minute', 'Month', 'Year', 'lead_paragraph', 'pub_date', 'web_url'}\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2aiii": {
     "name": "q2aiii",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 'Quarter' in news_df_dates.columns\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> news_df_dates.loc[938, 'Quarter'] == '2023Q1'\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> news_df_dates.loc[201, 'Quarter'] == '2020Q2'\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> news_df_dates.loc[734, 'Quarter'] == '2022Q3'\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> news_df_dates.loc[594, 'Quarter'] == '2021Q4'\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2bi": {
     "name": "q2bi",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> q2bi.upper() in ['A', 'B', 'C']\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2bii": {
     "name": "q2bii",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> q2bii.upper() in ['A', 'B', 'C']\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2c": {
     "name": "q2c",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> re.findall(modified_pattern, '\"Mitochondria is the powerhouse of the cell.\"') == ['\"Mitochondria is the powerhouse of the cell.\"']\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> re.findall(modified_pattern, 'there is no quote in this sentence') == []\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> re.findall(modified_pattern, 'Brandon said, \"Recently, DATA C100 course staffs have hosted a social event with staffs from DATA C8.\"') == ['\"Recently, DATA C100 course staffs have hosted a social event with staffs from DATA C8.\"']\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> re.findall(modified_pattern, '\"R is great,\" a TA said, \"but have you tried using Python?\"') == ['\"R is great,\" a TA said, \"but have you tried using Python?\"']\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> re.findall(modified_pattern, '\"How are your classes?\" the student asked. \"Super challenging! But a lot of fun!\" said their roommate.') == ['\"How are your classes?\"', '\"Super challenging! But a lot of fun!\"']\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2d": {
     "name": "q2d",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> news_df_dates.shape[0] == 1885\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(news_df_dates.columns) == {'GPT Model', 'Minute', 'Month', 'New Year', 'Quarter', 'Wordle', 'Year', 'Zoom', 'lead_paragraph', 'pub_date', 'web_url'}\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2e": {
     "name": "q2e",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> topic_mentions.shape == (24, 4)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(topic_mentions.columns) == {'Zoom', 'New Year', 'GPT Model', 'Wordle'}\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(topic_mentions.index) == {'2019Q1', '2019Q2', '2019Q3', '2019Q4', '2020Q1', '2020Q2', '2020Q3', '2020Q4', '2021Q1', '2021Q2', '2021Q3', '2021Q4', '2022Q1', '2022Q2', '2022Q3', '2022Q4', '2023Q1', '2023Q2', '2023Q3', '2023Q4', '2024Q1', '2024Q2', '2024Q3', '2024Q4'}\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3a": {
     "name": "q3a",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> (sentiment_analysis(less_polar_sentence)[0]['score'] < 0.8) == True\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3bi": {
     "name": "q3bi",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> news_df_filtered.shape == (1135, 11)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3bii": {
     "name": "q3bii",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 'article_sentiment' in news_df_sentiment.columns\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> news_df_sentiment.shape == (1054, 12)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(news_df_sentiment.columns) == {'GPT Model', 'Minute', 'Month', 'New Year', 'Quarter', 'Wordle', 'Year', 'Zoom', 'lead_paragraph', 'pub_date', 'article_sentiment', 'web_url'}\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> news_df_sentiment['article_sentiment'].iloc[1] <= 1 and news_df_sentiment['article_sentiment'].iloc[1] >= -1\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3di": {
     "name": "q3di",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> top_positive.shape[0] == 5\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> top_negative.shape[0] == 5\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
