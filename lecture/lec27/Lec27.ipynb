{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 27 â€“ Data 100, Spring 2025\n",
    "\n",
    "Data 100, Spring 2025\n",
    "\n",
    "[Acknowledgments Page](https://ds100.org/sp25/acks/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Setup\n",
    "\n",
    "You can run this notebook on the Jupyter Hub machines but you will need to setup an OpenAI account.  Alternatively, if you are running on your own computer you can also try to run a model locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Create an OpenAI account\n",
    "\n",
    "You can create a free account which has some initial free credits by going here:\n",
    "\n",
    "https://platform.openai.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will the need to get an API Key.  Save that api key to a local file called `openai.key`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with open(\"openai.key\", \"w\") as f:\n",
    "#     f.write(\"YOUR KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Install Python Tools\n",
    "\n",
    "Uncomment the following line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U openai langchain langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using OpenAI with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "openai_key = open(\"openai.key\", \"r\").readline()\n",
    "llm = OpenAI(openai_api_key=openai_key,\n",
    "             model_name=\"gpt-3.5-turbo-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm.invoke(\"What is the capital of California? Provide a short answer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for chunk in llm.stream(\"Write a short song about data science and large language models.\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Data Analytics\n",
    "\n",
    "We can use LLMs to help in analyzing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweets = pd.read_json(\"AOC_recent_tweets.txt\")\n",
    "list(tweets['full_text'][0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "Suppose I wanted to evaluate whether a tweet is attacking someone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Is the following text making a statement about minimum wage? You should answer either Yes or No.\n",
    "\n",
    "{text}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "questions = [prompt.format_map(dict(text=t)) for t in tweets['full_text'].head(20)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ask each of the LLMs to answer the questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "open_ai_answers = llm.batch(questions)\n",
    "open_ai_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "df = pd.DataFrame({\"OpenAI\": open_ai_answers, \n",
    "                   \"Text\": tweets['full_text'].head(20)})\n",
    "df[\"OpenAI\"] = df[\"OpenAI\"].str.contains(\"Y\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Working with Google Gemini Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to install Gemini API to use the code below.  You can install these APIs by uncommenting and running the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to obtain an API key.  Unfortunately, UC Berkeley has not yet enabled access to the Gemini API for Berkeley accounts but you can use any free Google account to obtain an API key.  You can obtain an API key by following the instructions [here](https://makersuite.google.com/app/apikey).\n",
    "\n",
    "Once you get an API Key you can put it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"gemini_key.txt\", \"w\") as f:\n",
    "#     f.write(\"YOUR KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_API_KEY = None\n",
    "if not GEMINI_API_KEY:\n",
    "    with open(\"gemini_key.txt\", \"r\") as f:\n",
    "        GEMINI_API_KEY = f.read().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then connect to the Gemini API using the following code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "models_df = pd.DataFrame(genai.list_models())\n",
    "models_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can obtain a model and use it to make a prediction. Here we will use the `\"gemini-2.5-flash\"` model, which is generally pretty good for a wide range of tasks. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "display(Markdown(models_df[models_df[\"name\"] == \"models/gemini-2.5-flash-preview-04-17\"]['description'].values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(\"gemini-2.5-flash-preview-04-17\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the model to generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(\"Why is Data 100 great?\")\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "img = Image(\"data100_logo.png\", width=200, height=200)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content([\n",
    "    \"\"\"What is going on in this picture I downloaded from \n",
    "    the Berkeley Data100 Course Website? \n",
    "    How does it related to Data Science\"\"\", img])\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can stream content back which could be useful for interacting with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "response = model.generate_content(\"Write a poem about Data Science.\", stream=True)\n",
    "\n",
    "output = \"\"\n",
    "for chunk in response:\n",
    "    output += chunk.text\n",
    "    clear_output(wait=True)\n",
    "    display(Markdown(output))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Gen AI for EDA\n",
    "\n",
    "We could use the model to help analyze our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_html(\"https://en.wikipedia.org/wiki/List_of_colleges_and_universities_in_California\")[1]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_model = genai.GenerativeModel(\"gemini-1.5-flash-8b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What is the mascot of {school}? Answer by only providing the mascot.\"\n",
    "df['mascot'] = df['Name'].apply(\n",
    "    lambda x: fast_model.generate_content(prompt.format(school=x)).text)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More EDA with Open AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "openai_key = open(\"openai.key\", \"r\").readline()\n",
    "client = OpenAI(openai_api_key=openai_key,\n",
    "             model_name=\"gpt-3.5-turbo-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating student feedback data\n",
    "feedback_data = {\n",
    "    'StudentID': [1, 2, 3, 4, 5],\n",
    "    'Feedback': [\n",
    "        'Great class, learned a lot! But I really did not like PCA.',\n",
    "        'The course was very informative and well-structured. Would prefer if lectures went faster. ',\n",
    "        'I found the assignments challenging but rewarding. But the midterm was brutal.',\n",
    "        'The lectures were engaging and the instructor was very knowledgeable.',\n",
    "        'I struggled with the linear algebra. I would recommend this class to anyone interested in data science.'\n",
    "    ],\n",
    "    'Rating': [5, 4, 4, 5, 5]\n",
    "}\n",
    "feedback_df = pd.DataFrame(feedback_data)\n",
    "feedback_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_schema = {\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": {\n",
    "            \"name\": \"issue_schema\",\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"Issue\": {\n",
    "                        \"description\": \"Any issues or concerns the user raised about the class.\",\n",
    "                        \"type\": \"string\"\n",
    "                    },\n",
    "                    \"Liked\": {\n",
    "                        \"description\": \"Any things the user liked about the class.\",\n",
    "                        \"type\": \"string\"\n",
    "                    },\n",
    "                    \"additionalProperties\": False\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "def process_feedback(feedback):\n",
    "    prompt = f\"\"\"Extract the following information in JSON format:\n",
    "    {{\n",
    "  \"Issue\": \"Any issues or concerns the user raised about the class.\",\n",
    "  \"Liked\": \"Any things the user liked about the class.\"\n",
    "  }}\n",
    "\n",
    "  Feedback: \"{feedback}\"\n",
    "\"\"\"\n",
    "    response = client.invoke(prompt)\n",
    "    import re, json\n",
    "    try:\n",
    "        json_match = re.search(r\"\\{.*\\}\", response, re.DOTALL)\n",
    "        return json.loads(json_match.group(0)) if json_match else {\"Issue\": \"\", \"Liked\": \"\"}\n",
    "    except:\n",
    "        return {\"Issue\": \"\", \"Liked\": \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = feedback_df[\"Feedback\"].apply(process_feedback)\n",
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "feedback_df.join(pd.DataFrame(responses.to_list()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
