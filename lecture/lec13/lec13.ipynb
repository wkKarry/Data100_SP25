{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⛰️ Lecture 13 – Data 100, Spring 2025\n",
    "\n",
    "Data 100, Spring 2025\n",
    "\n",
    "[Acknowledgments Page](https://ds100.org/sp25/acks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Fiting our Multiple Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the `penguins` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1123)>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/urllib/request.py:1342\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1341\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1342\u001b[0m     \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py:1255\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1255\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py:1301\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1300\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1301\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py:1250\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1250\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py:1010\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1010\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1013\u001b[0m \n\u001b[1;32m   1014\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py:950\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 950\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py:1424\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1422\u001b[0m     server_hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[0;32m-> 1424\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1425\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ssl.py:500\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    495\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    496\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    497\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    498\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ssl.py:1040\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1040\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ssl.py:1309\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1308\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1309\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1123)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load in the penguins dataset provided by seaborn package\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpenguins\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Filter to only include Adelie species and remove any rows with missing values\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecies\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdelie\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdropna()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/seaborn/utils.py:572\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(name, cache, data_home, **kws)\u001b[0m\n\u001b[1;32m    570\u001b[0m cache_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(get_data_home(data_home), os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(url))\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(cache_path):\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mget_dataset_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    573\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not one of the example datasets.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    574\u001b[0m     urlretrieve(url, cache_path)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/seaborn/utils.py:499\u001b[0m, in \u001b[0;36mget_dataset_names\u001b[0;34m()\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_dataset_names\u001b[39m():\n\u001b[1;32m    494\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Report available example datasets, useful for reporting issues.\u001b[39;00m\n\u001b[1;32m    495\u001b[0m \n\u001b[1;32m    496\u001b[0m \u001b[38;5;124;03m    Requires an internet connection.\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \n\u001b[1;32m    498\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 499\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATASET_NAMES_URL\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m resp:\n\u001b[1;32m    500\u001b[0m         txt \u001b[38;5;241m=\u001b[39m resp\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    502\u001b[0m     dataset_names \u001b[38;5;241m=\u001b[39m [name\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m txt\u001b[38;5;241m.\u001b[39mdecode()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/urllib/request.py:214\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/urllib/request.py:517\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    514\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[1;32m    516\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[0;32m--> 517\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[1;32m    520\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/urllib/request.py:534\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    533\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m--> 534\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m    535\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/urllib/request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    493\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 494\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/urllib/request.py:1385\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[0;32m-> 1385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/urllib/request.py:1345\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1342\u001b[0m         h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[1;32m   1343\u001b[0m                   encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m   1344\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[0;32m-> 1345\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[1;32m   1346\u001b[0m     r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1123)>"
     ]
    }
   ],
   "source": [
    "# Load in the penguins dataset provided by seaborn package\n",
    "df = sns.load_dataset(\"penguins\")\n",
    "\n",
    "# Filter to only include Adelie species and remove any rows with missing values\n",
    "df = df[df[\"species\"] == \"Adelie\"].dropna()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we could measure flippers and weight easily, but not bill dimensions.\n",
    "How can we predict **bill depth** from flipper length and/or body mass?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demo purposes, we'll drop all columns except the variables whose relationships we're interested in modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to create a linear regression model that predicts a penguin's **bill depth** $y$ using both their **flipper length** $x_1$ and **body mass** $x_2$, plus an intercept term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\Large \\hat{y} = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2$$\n",
    "\n",
    "Another way to write this:\n",
    "\n",
    "$$ \\widehat{\\texttt{bill\\_depth\\_mm}} = \\theta_0 + \\theta_1 * \\texttt{flipper\\_length\\_mm} + \\theta_2 * \\texttt{body\\_mass\\_g} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS Approach 1: Use Solution to Normal Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw in last lecture that we can model the above multiple linear regression equation using matrix multiplication:\n",
    "\n",
    "$$ \\large \\hat{\\mathbb{Y}} = \\mathbb{X} \\theta$$\n",
    "\n",
    "The optimal $\\hat{\\theta}$ that minimizes MSE also solves the **normal equation**:\n",
    "\n",
    "$$ \\left( \\mathbb{X}^T \\mathbb{X} \\right) \\hat{\\theta} = \\mathbb{X}^T \\mathbb{Y}$$\n",
    "\n",
    "If $\\mathbb{X}$ is full column rank, then there is a unique solution to $\\hat{\\theta}$:\n",
    "\n",
    "$$\\large \\hat{\\theta} = \\left( \\mathbb{X}^T \\mathbb{X} \\right)^{-1} \\mathbb{X}^T \\mathbb{Y}$$\n",
    "\n",
    "> Note: This derivation is one of the most challenging in the course, especially for those of you who are learning linear algebra during the same semester. Be kind to yourself! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "---\n",
    "\n",
    "Let's try this in code. We have to add a bias column to the design matrix if we want to include an intercept in the model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the design matrix X as a dataframe and add a bias column\n",
    "X = df[[\"flipper_length_mm\", \"body_mass_g\"]]\n",
    "X[\"bias\"] = 1\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the outcome vector y\n",
    "y = df[\"bill_depth_mm\"]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the solution to the normal equation if $\\mathbb{X}$ is full column rank:\n",
    "\n",
    "$$\\hat{\\theta} = \\left( \\mathbb{X}^T \\mathbb{X} \\right)^{-1} \\mathbb{X}^T \\mathbb{Y}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M.T transposes a matrix M\n",
    "# X @ Y multiplies matrices X and Y\n",
    "# np.linalg.inv(M) finds the inverse of a matrix M\n",
    "# By default, the dataframe X will be silently converted to a matrix\n",
    "theta_using_normal_equation = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "theta_using_normal_equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, our fitted model is as follows:\n",
    "\n",
    "$$ \\widehat{\\texttt{bill\\_depth\\_mm}} = 11 + 0.0098 * \\texttt{flipper\\_length\\_mm} + 0.0015 * \\texttt{body\\_mass\\_g} $$\n",
    "\n",
    "> The bias column is the last column in our design matrix. So, the intercept (11) appears last in the parameter list. More often, the bias column is the first column of the design matrix.\n",
    "\n",
    "Note: The code above is inefficient. We won't go into this in Data 100, but it's better to use `np.linalg.solve` rather than computing the explicit matrix inverse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solves for θ in (XTX)θ = XTy using a system of linear equations\n",
    "np.linalg.solve(X.T @ X, X.T @ y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Predictions\n",
    "We'll save the predictions in a column so we can compare them against predictions from `sklearn` in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe representation of the design matrix to a numpy array, \n",
    "# and then multiply it by the theta vector to get the predicted outcomes.\n",
    "# Yhat = Xθ\n",
    "df[\"pred_bill_depth_mm\"] = X.to_numpy() @ theta_using_normal_equation\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "**Instructor Note: Return to Lecture!**\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "### Using `sklearn` to fit our Multiple Linear Regression Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternate approach to optimize our model is to use the `sklearn.linear_model.LinearRegression` class. [(Documentation)](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the LinearRegression class\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Create an `sklearn` object.**\n",
    "\n",
    "    First we create a model. At this point the model has not been fit so it has no parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a blank LinearRegression model object\n",
    "model = LinearRegression()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **`fit` the object to data.**\n",
    "\n",
    "Then we \"fit\" the model, which means computing the parameters that minimize the loss function. \n",
    "    \n",
    "The first argument of the fit function should be a matrix (or DataFrame), and the second should be the observations we're trying to predict. \n",
    "\n",
    "Note: The `LinearRegression` class is hard coded to use the **MSE** as its loss function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the linear regression model to the data\n",
    "model.fit(\n",
    "    X=df[[\"flipper_length_mm\", \"body_mass_g\"]], \n",
    "    y=df[\"bill_depth_mm\"]\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Analyze fit or call `predict`.**\n",
    "\n",
    "    Now that our model is trained, we can ask it questions. \n",
    "    \n",
    "    The code below asks the model to estimate the bill depth (in mm) for a penguin with a 185 mm flipper length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a prediction (yhat) by providing the X values to the model.\n",
    "# The input to .predict() is a list of lists. \n",
    "# Each sub-list contains the X values for each observation.\n",
    "# That's why there are double brackets!\n",
    "model.predict([[185, 3750.0]]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also ask the model to generate a series of predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also provide a design matrix or dataframe to .predict()\n",
    "df[\"sklearn_preds\"] = model.predict(df[[\"flipper_length_mm\", \"body_mass_g\"]])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the predictions, we see that they are exactly the same as what we calculated with our analytic formula!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyze parameters.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can ask the model for its intercept and slope with `_intercept` and `_coef`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is one intercept term in the model\n",
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are two slope terms in the model\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, our fitted model is as follows:\n",
    "\n",
    "$$ \\widehat{\\texttt{bill\\_depth\\_mm}} = 11 + 0.0098 * \\texttt{flipper\\_length\\_mm} + 0.0015 * \\texttt{body\\_mass\\_g} $$\n",
    "\n",
    "The parameters are the same as with our analytic formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vs. analytical solutions\n",
    "theta_using_normal_equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They look the same, but why are they out of order...?\n",
    "\n",
    "- Remember our order of columns used for normal equation! The bias column is last in the design matrix, so the intercept appears last in the parameter list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Fit\n",
    "We can visualize this data in three dimensions, but for many (most) real-world problems this will not be possible (or helpful).\n",
    "\n",
    "Note, the following code is out of scope for this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(df, x=\"flipper_length_mm\", y=\"body_mass_g\", z=\"bill_depth_mm\")\n",
    "\n",
    "# Create a grid of points to evaluate plane\n",
    "grid_resolution = 2\n",
    "(u,v) = np.meshgrid(\n",
    "    np.linspace(df[\"flipper_length_mm\"].min(), df[\"flipper_length_mm\"].max(), grid_resolution),\n",
    "    np.linspace(df[\"body_mass_g\"].min(), df[\"body_mass_g\"].max(), grid_resolution))\n",
    "features = pd.DataFrame({\"flipper_length_mm\": u.flatten(),\n",
    "                         \"body_mass_g\": v.flatten()})\n",
    "# Make predictions at every point on the grid\n",
    "zs = model.predict(features)\n",
    "\n",
    "# create the Surface\n",
    "fig.add_trace(go.Surface(x=u, y=v, z= zs.reshape(u.shape), opacity=0.9, showscale=False))\n",
    "fig.update_layout(autosize=False, width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the predictions all lie in a plane. In higher dimensions, the predictions all lie in a \"hyperplane\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyze performance.**\n",
    "\n",
    "The `sklearn` package also provides a function `mean_squared_error()` ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)) that computes the MSE from a list of observations and predictions. This avoids us having to manually compute MSE by first computing residuals.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the MSE for a prediction vector and a ground truth outcome vector\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(df[\"bill_depth_mm\"], df[\"sklearn_preds\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "**Instructor Note: Return to Lecture!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## Bonus Demo\n",
    "\n",
    "Later in the semester we will learn about other models. However, you already know enough to start using other techniques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sklearn approach is flexible to different model types, like trees! \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_model = DecisionTreeRegressor()\n",
    "\n",
    "tree_model.fit(\n",
    "    X=df[[\"flipper_length_mm\", \"body_mass_g\"]], \n",
    "    y=df[\"bill_depth_mm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sklearn_dt_preds\"] = tree_model.predict(df[[\"flipper_length_mm\", \"body_mass_g\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean_squared_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmean_squared_error\u001b[49m(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbill_depth_mm\u001b[39m\u001b[38;5;124m\"\u001b[39m], df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msklearn_dt_preds\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean_squared_error' is not defined"
     ]
    }
   ],
   "source": [
    "mean_squared_error(df[\"bill_depth_mm\"], df[\"sklearn_dt_preds\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lower error! A better model? Let's visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(df, x=\"flipper_length_mm\", y=\"body_mass_g\", z=\"bill_depth_mm\")\n",
    "\n",
    "# Create a grid of points to evaluate plane\n",
    "grid_resolution = 20\n",
    "(u,v) = np.meshgrid(\n",
    "    np.linspace(df[\"flipper_length_mm\"].min(), df[\"flipper_length_mm\"].max(), grid_resolution),\n",
    "    np.linspace(df[\"body_mass_g\"].min(), df[\"body_mass_g\"].max(), grid_resolution))\n",
    "features = pd.DataFrame({\"flipper_length_mm\": u.flatten(),\n",
    "                         \"body_mass_g\": v.flatten()})\n",
    "\n",
    "# Make predictions at every point on the grid\n",
    "zs = tree_model.predict(features) #<------------------ Only change\n",
    "\n",
    "# create the Surface\n",
    "fig.add_trace(go.Surface(x=u, y=v, z= zs.reshape(u.shape), opacity=0.9, showscale=False))\n",
    "fig.update_layout(autosize=False, width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "\n",
    "# Minimizing an Arbitrary 1D Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to find the value of $x$ that minimizes the arbitrary function given below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{1}{10}\\left(x^4 - 15x^3 + 80 x^2 - 180x + 144\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return (x**4 - 15*x**3 + 80*x**2 - 180*x + 144)/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimization via visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(1, 6.75, 200)\n",
    "fig = px.line(y = f(x), x = x)\n",
    "fig.update_layout(font_size = 16)\n",
    "fig.update_layout(autosize=False, width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that the minimum is somewhere around 5.3ish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Naive Approach: Guess and Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another approach would be to guess and check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.argmin returns the index of the smallest value in an array\n",
    "# This function returns the x value corresponding to the smallest\n",
    "# value of f(x), for an input array of x values\n",
    "def simple_minimize(f, xs):\n",
    "    y = [f(x) for x in xs]\n",
    "    return xs[np.argmin(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guesses = [5.3, 5.31, 5.32, 5.33, 5.34, 5.35]\n",
    "simple_minimize(f, guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process is essentially the same as before where we made a graphical plot, it's just that we're only looking at a few selected points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.linspace(1, 7, 200)\n",
    "sparse_xs = np.linspace(1.5, 6.5, 5)\n",
    "\n",
    "ys = f(xs)\n",
    "sparse_ys = f(sparse_xs)\n",
    "\n",
    "fig = px.line(x = xs, y = f(xs))\n",
    "fig.add_scatter(x = sparse_xs, y = f(sparse_xs), mode = \"markers\", marker_size=16)\n",
    "fig.update_layout(showlegend= False)\n",
    "fig.update_layout(autosize=False, width=800, height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This basic approach suffers from three major flaws:\n",
    "1. If the minimum is outside our range of guesses, the answer will be completely wrong.\n",
    "2. Even if our range of guesses is correct, if the guesses are too coarse, our answer will be inaccurate.\n",
    "3. It is not computationally efficient, considering potentially vast numbers of bad guesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "\n",
    "### `scipy.optimize.minimize`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to minimize this mathematical function is to use the `scipy.optimize.minimize` function. It takes a function and a starting guess and tries to find the minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# x0 is a starting guess for the value of x that minimizes f.\n",
    "# minimize() will iteratively try to improve this guess.\n",
    "# Don't worry about all of the details of the output.\n",
    "# The important part is \"x\", the value of x that minimizes f.\n",
    "minimize(f, x0 = 3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can this one line of code find the minimum of any mathematical function so quickly? \n",
    "\n",
    "Behind the scenes, `scipy.optimize.minimize` uses a collection of techniques to compute the minimizing value of a function. Many of these techniques operate on numerical approximations to the gradient.\n",
    "\n",
    "In this lecture, we will learn the basics of gradient descent, then implement it ourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "**Instructor Note: Return to Lecture!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br><br>\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "\n",
    "\n",
    "# Descending with Derivatives\n",
    "\n",
    "\n",
    "Instead of choosing all of our guesses ahead of time, we can instead start from a single guess and try to iteratively improve on our choice. \n",
    "\n",
    "The key insight: \n",
    "\n",
    "- If the derivative of the function is negative, that means the function is decreasing, so we should go to the right (i.e., pick a bigger x). \n",
    "\n",
    "- If the derivative of the function is positive, that means the function is increasing, so we should go to the left (i.e., pick a smaller x).\n",
    "\n",
    "Thus, the derivative tells us which way to go.\n",
    "\n",
    "Desmos demo: [https://www.desmos.com/calculator/twpnylu4lr](https://www.desmos.com/calculator/twpnylu4lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the derivative of my arbitrary function:\n",
    "\n",
    "\\begin{align}\n",
    "f(x) & = \\frac{1}{10}\\left(x^4 - 15x^3 + 80 x^2 - 180x + 144\\right)\\\\\n",
    "\\frac{d}{d x} f(x) & = \\frac{1}{10}\\left(4x^3 - 45x^2 + 160 x - 180\\right)\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv_f(x):\n",
    "    return (1/10) * (4*x**3 - 45*x**2 + 160*x - 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_line = go.Scatter(x = xs, y = f(xs), mode = \"lines\", name = \"f\")\n",
    "derivative_line = go.Scatter(x = xs, y = deriv_f(xs), \n",
    "                             mode = \"lines\", name = \"f'\", line = {\"dash\": \"dash\"})\n",
    "# add horizontal line at 0\n",
    "zero_line = go.Scatter(x = xs, y = 0*xs, mode = \"lines\", name='f(x) = 0')\n",
    "roots = np.array([2.3927, 3.5309, 5.3263]) # computed using algorithm\n",
    "root_markers = go.Scatter(x = np.array(roots), y = 0*roots, \n",
    "                         mode = \"markers\", name = \"f'(x) = 0\", marker_size = 12)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_traces([f_line, derivative_line, zero_line, root_markers])\n",
    "fig.update_layout(font_size = 20, yaxis_range=[-1, 3])\n",
    "fig.update_layout(autosize=False, width=800, height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the derivative at a point show which the direction to move?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 4.3\n",
    "fig = go.Figure()\n",
    "fig.add_trace(f_line)\n",
    "# Adding a red arrow in the direction of the gradient.\n",
    "#  Note the arrow is just a direction along the x dimension \n",
    "#  (the y position is just for illustrative purposes)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[x, x - deriv_f(x)], y=[f(x), f(x)],  \n",
    "    marker= dict(size=10,symbol= \"arrow-bar-up\", angleref=\"previous\"),\n",
    "    name=\"-f'(x0)\"\n",
    "    ))\n",
    "# Add the Green circle for our guess\n",
    "fig.add_trace(go.Scatter(x=[x],y=[f(x)], \n",
    "                         marker_color=\"green\", marker_size=12,\n",
    "                         mode=\"markers\", name=\"x0\"))\n",
    "fig.update_layout(font_size = 20, yaxis_range=[-1, 3])\n",
    "fig.update_layout(autosize=False, width=800, height=600)\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually Descending with Derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Armed with this knowledge, let's try to see if we can use the derivative to optimize the function.\n",
    "\n",
    "We start by making some guess for the minimizing value of $x$. Then, we look at the derivative of the function at this value of $x$, and step downhill in the *opposite* direction. We can express our new rule as a recurrence relation:\n",
    "\n",
    "$$x^{(t+1)} = x^{(t)} - \\frac{d}{dx} f(x^{(t)})$$\n",
    "\n",
    "We obtain **our next guess** for the minimizing value of $x$ at timestep $t+1$ ($x^{(t+1)}$) by taking the guess **our last guess** ($x^{(t)}$) and subtracting the **derivative of the function** at that point ($\\frac{d}{dx} f(x^{(t)})$).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the algorithm one step at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `x` is our current guess for the minimum.\n",
    "# `derivative` is a function that takes in a single value and \n",
    "# returns the value of the derivative of f at the given input value.\n",
    "def take_one_step(x, derivative):\n",
    "    new_x = x - derivative(x)\n",
    "    return new_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Starting with an initial guess of 4.0 and taking 10 steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 4.0\n",
    "steps = [x]\n",
    "for i in range(10):\n",
    "    x = take_one_step(x, deriv_f)\n",
    "    steps.append(x) \n",
    "\n",
    "print(steps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the optimization steps\n",
    "\n",
    "Note: The following visualization code is out-of-scope for Data 100, but you should understand the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is out-of-scope for data-100 but could be fun to learn.\n",
    "def plot_steps(steps, f = f, f_line = f_line):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(f_line)\n",
    "    fig.add_trace(go.Scatter(x = steps, y = [f(s) for s in steps], \n",
    "                             mode = \"lines+markers\", line = {\"dash\": \"dash\", \"color\": \"red\"},\n",
    "                             name = \"Path\", \n",
    "                             marker_symbol=\"arrow\",\n",
    "                             marker_angleref=\"previous\",\n",
    "                             marker_standoff=4,\n",
    "                             marker_size = 16))\n",
    "    fig.add_trace(go.Scatter(x = steps, y = [f(s) for s in steps], \n",
    "                             mode = \"markers\", \n",
    "                             name = \"Path\",\n",
    "                             marker_color=\"red\",\n",
    "                             showlegend=False,\n",
    "                             marker_size = 8))\n",
    "    fig.update_layout(font_size = 20)\n",
    "    fig.update_layout(autosize=False, width=800, height=600)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_steps(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking pretty good! We do have a problem though – once we arrive close to the minimum value of the function, our guesses \"bounce\" back and forth past the minimum without ever reaching it.\n",
    "\n",
    "- In other words, each step we take when updating our guess moves us too far. We can address this by decreasing the size of each step. \n",
    "\n",
    "Let's update our algorithm to use a **learning rate** (also sometimes called the step size), which controls how far we move with each update. We represent the learning rate with $\\alpha$. \n",
    "\n",
    "$$x^{(t+1)} = x^{(t)} - \\alpha \\frac{d}{dx} f(x^{(t)})$$\n",
    "\n",
    "A small $\\alpha$ means that we will take small update steps; a large $\\alpha$ means we will take large steps. \n",
    "\n",
    "Let's update our function to use $\\alpha=0.3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_one_step_lr(x, alpha, derivative):\n",
    "    # Find our new guess using the recurrence relation\n",
    "    new_x = x - alpha * derivative(x)\n",
    "    return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 4.0\n",
    "steps = [x]\n",
    "for i in range(15):\n",
    "    x = take_one_step_lr(x, alpha=0.3, derivative = deriv_f)\n",
    "    print(x)\n",
    "    steps.append(x) \n",
    "\n",
    "plot_steps(steps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "**Instructor Note: Return to Lecture!**\n",
    "\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Gradient Descent Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process we just explored above is called **gradient descent** – we identify the direction of greatest change of a function (its **gradient**) with respect to the variable we wish to optimize, then *descend* down to the minimum of the function. \n",
    "\n",
    "$$\n",
    "x^{(t+1)} = x^{(t)} -  \\alpha \\frac{d}{dx} f(x)\n",
    "$$\n",
    "\n",
    "In the cell below, we define `gradient_descent`, which runs the gradient descent algorithm for a specified number `n` of updates and stores all guesses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(deriv_f, initial_guess, alpha, T):\n",
    "    \"\"\"Performs T steps of gradient descent on df using learning rate alpha starting\n",
    "       from initial_guess. Returns a numpy array of all guesses over time.\"\"\"\n",
    "    guesses = [initial_guess]\n",
    "    current_guess = initial_guess\n",
    "    while len(guesses) < T:\n",
    "        current_guess = current_guess - alpha * deriv_f(current_guess)\n",
    "        guesses.append(current_guess)\n",
    "        \n",
    "    return np.array(guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we see a visualization of the trajectory taken by this algorithm. \n",
    "\n",
    "**Try modifying the `initial_guess`, learning rate `alpha`, and number of updates (i.e., time steps) `T`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory = gradient_descent(deriv_f, initial_guess=1.6, alpha=0.75, T=20)\n",
    "print(trajectory)\n",
    "plot_steps(trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory = gradient_descent(deriv_f, initial_guess=6, alpha=0.75, T=20)\n",
    "print(trajectory)\n",
    "plot_steps(trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we've simply run our algorithm a fixed number of times. More sophisticated implementations will stop based on a variety of different stopping criteria, e.g., error getting too small, error getting too large, etc. We will not discuss these in our course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next part, we'll return to the world of real data and see how this procedure might be useful for optimizing models.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Instructor Note: Return to Lecture!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Gradient Descent on a 1D Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall our modeling workflow from the past few lectures: \n",
    "* Define a model with some parameters $\\theta_i$\n",
    "* Choose a loss function \n",
    "* Select the values of $\\theta_i$ that minimize the loss function on the data\n",
    "\n",
    "Gradient descent is a powerful technique for completing this last task. By applying the gradient descent algorithm, we can select values for our parameters $\\theta_i$ that will lead to the model having minimal loss on the training data.\n",
    "\n",
    "When using gradient descent in a modeling context:\n",
    "* We make guesses for the minimizing $\\theta_i$\n",
    "* We compute the derivative of the loss function $L$\n",
    "\n",
    "Using our gradient descent rule from before:\n",
    "\n",
    "$$\\theta^{(t+1)} = \\theta^{(t)} - \\alpha \\frac{d}{d\\theta} L(\\theta^{(t)})$$\n",
    "\n",
    "To see this in action, let's consider a case where we have a simple linear model with no intercept. \n",
    "\n",
    "$$\\hat{y} = \\theta_1 x$$\n",
    "\n",
    "Let's apply our `gradient_descent` function from before to optimize our model on the `tips` dataset. We will try to select the best parameter $\\theta_i$ to predict the `tip` $y$ from the `total_bill` $x$.\n",
    "\n",
    "$$\n",
    "\\widehat{\\texttt{tip}} = \\texttt{total\\_bill} * \\theta_1\n",
    "$$\n",
    "\n",
    "We want to find the parameter $\\theta_1$ such that the mean squared error is minimized. Our loss function is:\n",
    "\n",
    "$$L(\\theta) = MSE(\\theta) = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\theta_1x_i)^2$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sns.load_dataset(\"tips\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are want to predict the tip using the total bill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[\"total_bill\"]\n",
    "y_obs = df[\"tip\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the value of the MSE on our dataset for different possible choices of $\\theta_1$. To optimize our model, we want to select the value of $\\theta_1$ that leads to the lowest MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_single_arg(theta_1):\n",
    "    \"\"\"Returns the MSE on our data for the given theta1\"\"\"\n",
    "    y_hat = theta_1 * x\n",
    "    return np.mean((y_hat - y_obs) ** 2) \n",
    "\n",
    "thetas = np.linspace(-1.5, 1, 100)\n",
    "\n",
    "mse_line = go.Scatter(x = thetas, y = [mse_single_arg(theta_1) for theta_1 in thetas], mode = \"lines\", name = \"MSE\")\n",
    "fig = go.Figure()\n",
    "fig.add_trace(mse_line)\n",
    "fig.update_layout(autosize=False, width=800, height=600, xaxis_title=\"theta_1\", yaxis_title=\"MSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply gradient descent, we need to compute the derivative of the loss function with respect to our parameter $\\theta_1$. This comes out to be:\n",
    "\n",
    "$$\\frac{d}{d\\theta_1} L(\\theta^{(t)}) = \\frac{-2}{n} \\sum_{i=1}^n (y_i - \\theta_1^{(t)}x_i)x_i$$\n",
    "\n",
    "Here, we denote our parameter as $\\theta_1^{(t)}$ to remind ourselves that we compute the derivative assuming $\\theta_i$ has the value of our *current* guess. \n",
    "\n",
    "Our gradient descent update rule is:\n",
    "\n",
    "$$\\theta_1^{(t+1)} = \\theta_1^{(t)} - \\alpha \\frac{-2}{n} \\sum_{i=1}^n (y_i - \\theta_1^{(t)}x_i)x_i$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use our gradient descent function, we need to compute the derivative of the MSE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivative of the MSE with respect to `theta_1` is implemented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv_mse_single_arg(theta_1):\n",
    "    \"\"\"Returns the derivative of the MSE on our data for the given theta1\"\"\"\n",
    "    y_hat = theta_1 * x\n",
    "    return np.mean(-2 * (y_obs - y_hat) * x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can apply gradient descent to select a value for $\\theta_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trajectory = gradient_descent(deriv_mse_single_arg, initial_guess=-0.5, alpha=0.0001, T=100)\n",
    "print(f\"Final guess for theta_1: {trajectory[-1]}\")\n",
    "plot_steps(trajectory,  mse_single_arg,  mse_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "**Instructor Note: Return to Lecture!**\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Gradient Descent on Multi-Dimensional Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose we improve our model so that we want to predict the tip from the total_bill plus a constant offset, in other words:\n",
    "\n",
    "$$\\textrm{tip} = \\theta_0 + \\theta_1 \\textrm{bill}$$\n",
    "\n",
    "Our simple linear regression model has *two* parameters, $\\theta_0$ and $\\theta_1$. We need to optimize both of them.\n",
    "\n",
    "Fortunately, gradient descent readily extends to models with multiple dimenions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a 2D MSE Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will generate our predictions as $$\\hat{y} = \\theta_0 + \\theta_1 x_1$$\n",
    "\n",
    "In the cell below, we add a bias term to our data to represent the constant intercept $\\theta_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_with_bias = df.copy()\n",
    "tips_with_bias[\"bias\"] = 1\n",
    "tips_with_bias = tips_with_bias[[\"bias\", \"total_bill\"]]\n",
    "tips_with_bias.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tips_with_bias\n",
    "y = df[\"tip\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this problem, we'll assume we want to minimize the mean squared error of our predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(theta):\n",
    "    y_hat = X @ theta\n",
    "    return np.mean((y - y_hat) ** 2)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this function, we can visualize our loss function. Because we now want to understand how the loss changes with respect to *two* parameters, we create a **loss surface**. Each point on the surface represents the loss of the model for a particular choice of $\\theta_0$ and $\\theta_1$.\n",
    "\n",
    "\n",
    "The cell below uses lots of syntax you've never seen. No need to worry about any unfamiliar plotting code; for now, focus on the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "uvalues = np.linspace(-1, 5, 20)\n",
    "vvalues = np.linspace(-0.1, 0.35, 20)\n",
    "(u,v) = np.meshgrid(uvalues, vvalues)\n",
    "thetas = np.vstack((u.flatten(),v.flatten()))\n",
    "\n",
    "\n",
    "MSE = np.array([mse_loss(t) for t in thetas.T])\n",
    "\n",
    "loss_surface = go.Surface(x=u, \n",
    "    y=v, z=np.reshape(MSE, u.shape),\n",
    "    contours = {\"z\": {\"show\": True, \"start\": 0, \"end\": 50, \"size\": 2, \"color\": \"white\"}})\n",
    "\n",
    "# This is an approximate guess for the optimal point.\n",
    "ind = np.argmin(MSE)\n",
    "optimal_point = go.Scatter3d(name = \"Optimal Point\",\n",
    "    x = [thetas.T[ind,0]], y = [thetas.T[ind,1]], \n",
    "    z = [MSE[ind]],\n",
    "    marker=dict(size=10, color=\"red\"))\n",
    "\n",
    "fig = go.Figure(data=[loss_surface, optimal_point])\n",
    "fig.update_layout(scene = dict(\n",
    "    xaxis_title = \"theta0\",\n",
    "    yaxis_title = \"theta1\",\n",
    "    zaxis_title = \"MSE\"), autosize=False, width=800, height=600)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play around with the plot above. We have marked the lowest point on the surface in red – this is the combination of $\\theta_0$ and $\\theta_1$ that leads to the lowest MSE for the model.\n",
    "\n",
    "Alternatively, we can visualize a bird's-eye view of the loss surface from above using a contour plot: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour = go.Contour(x=u[0], y=v[:, 0], z=np.reshape(MSE, u.shape), \n",
    "                     contours=dict(start=0, end=70,size=2))\n",
    "fig = go.Figure(contour)\n",
    "fig.update_layout(\n",
    "    xaxis_title = \"theta0\",\n",
    "    yaxis_title = \"theta1\", autosize=False, width=800, height=600)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying Gradient Descent in 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with multidimensional models, we optimize a *vector* of parameters. Our new update rule is:\n",
    "\n",
    "$$\\vec{\\theta}^{(t+1)} = \\vec{\\theta}^{(t)} - \\alpha \\nabla_{\\vec{\\theta}} L(\\vec{\\theta}^{(t)})$$\n",
    "\n",
    "Where $\\nabla_{\\vec{\\theta}} L(\\vec{\\theta}^{(t)})$ is the **gradient** of the loss function. It is the vector of the partial derivatives of loss with respect to each parameter $\\theta_i$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's derive the gradient of the loss for our problem:\n",
    "\n",
    "$$\n",
    "\\textbf{L}(\\theta) = \\textbf{MSE}(\\theta) = \\frac{1}{n}\\sum_{i=1}^n \\left(y_i - \\left(\\theta_0 + \\theta_1 x_i\\right)\\right)^2\n",
    "$$\n",
    "\n",
    "Computing the partial derivatives: \n",
    "\\begin{align}\n",
    "\\frac{\\partial }{\\partial \\theta_0}\\textbf{L}(\\theta) & = \n",
    "\\frac{1}{n}\\sum_{i=1}^n \\frac{\\partial }{\\partial \\theta_0}\\left(y_i - \\left(\\theta_0 + \\theta_1 x_i\\right)\\right)^2 \\\\\n",
    "& = \n",
    "\\frac{1}{n}\\sum_{i=1}^n 2\\left(y_i - \\left(\\theta_0 + \\theta_1 x_i\\right)\\right) \\left(- \\frac{\\partial }{\\partial \\theta_0}\\left(\\theta_0 + \\theta_1 x_i\\right)\\right) \\\\\n",
    "& =\n",
    "\\frac{1}{n}\\sum_{i=1}^n 2\\left(y_i - \\left(\\theta_0 + \\theta_1 x_i\\right)\\right) \\left(- 1 \\right) \\\\\n",
    "& = \n",
    "\\frac{-2}{n}\\sum_{i=1}^n \\left(y_i - \\left(\\theta_0 + \\theta_1 x_i\\right)\\right)  \\\\\n",
    "\\frac{\\partial }{\\partial \\theta_1}\\textbf{L}(\\theta) & = \n",
    "\\frac{1}{n}\\sum_{i=1}^n \\frac{\\partial }{\\partial \\theta_1}\\left(y_i - \\left(\\theta_0 + \\theta_1 x_i\\right)\\right)^2 \\\\\n",
    "& = \n",
    "\\frac{1}{n}\\sum_{i=1}^n 2\\left(y_i - \\left(\\theta_0 + \\theta_1 x_i\\right)\\right) \\left(- \\frac{\\partial }{\\partial \\theta_1}\\left(\\theta_0 + \\theta_1 x_i\\right)\\right) \\\\\n",
    "& =\n",
    "\\frac{1}{n}\\sum_{i=1}^n 2\\left(y_i - \\left(\\theta_0 + \\theta_1 x_i\\right)\\right) \\left(- x_i \\right) \\\\\n",
    "& = \n",
    "\\frac{-2}{n}\\sum_{i=1}^n \\left(y_i - \\left(\\theta_0 + \\theta_1 x_i\\right)\\right) x_i  \\\\\n",
    "\\end{align}\n",
    "\n",
    "In the above we used the chain rule: \n",
    "$$\n",
    "\\frac{\\partial}{\\partial\\theta}f(g(\\theta))=\\left.\\left(\\frac{\\partial}{\\partial u}f(u) \\right)\\right\\rvert_{u=\\theta}\\,\\frac{\\partial}{\\partial\\theta}g(\\theta)\n",
    "$$\n",
    "\n",
    "We obtain the gradient:\n",
    "\n",
    "$$\n",
    "\\nabla \\textbf{L}(\\theta) = \n",
    "\\begin{bmatrix}\n",
    "\\frac{-2}{n}\\sum_{i=1}^n \\left(y_i - \\left(\\theta_0 + \\theta_1 x_i\\right)\\right) \\\\\n",
    "\\frac{-2}{n}\\sum_{i=1}^n \\left(y_i - \\left(\\theta_0 + \\theta_1 x_i\\right)\\right) x_i \n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we define helper functions to compute the gradient of MSE with respect to our two parameters $\\theta_0$ and $\\theta_1$, stored in the array `theta`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_gradient(theta):\n",
    "    \"\"\"Returns the gradient of the MSE on our data for the given theta\"\"\"\n",
    "    x1 = X.iloc[:, 1]\n",
    "    dth0 = np.mean(-2 * (y - (theta[0] + theta[1]*x1)))\n",
    "    dth1 = np.mean(-2 * (y - (theta[0] + theta[1]*x1)) * x1)\n",
    "    return np.array([dth0, dth1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use our `gradient_descent` function from before to optimize $\\theta_0$ and $\\theta_1$ at the same time! The final estimates for the ideal model parameters are very similar to the guesses we may have made simply by inspecting the plot of the loss surface from before. \n",
    "\n",
    "The cell below may take a moment to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that `initial_guess` is now an array of size 2.\n",
    "guesses = gradient_descent(mse_gradient, initial_guess=np.array([1, .5]), alpha=0.001, T=10000)\n",
    "\n",
    "pd.DataFrame(guesses, columns=[\"theta_0\", \"theta_1\"]).tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing with the scipy minimize function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize(mse_loss, x0 = [0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can actually provide the gradient information to the scipy optimizer to get an even faster solution. This is out of scope for Data 100!\n",
    "\n",
    "> `jac` stands for [Jacobian](https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize(mse_loss, x0 = [0,0], jac=mse_gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "**Instructor Note: Return to Lecture!**\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Stochastic Gradient Descent on Multi-Dimensional Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_gradient(theta, X, y):\n",
    "    \"\"\"Returns the gradient of the MSE on our data for the given theta\"\"\"\n",
    "    x0 = X.iloc[:, 0]\n",
    "    x1 = X.iloc[:, 1]\n",
    "    dth0 = np.mean(-2 * (y - theta[0]*x0 - theta[1]*x1) * x0)\n",
    "    dth1 = np.mean(-2 * (y - theta[0]*x0 - theta[1]*x1) * x1)\n",
    "    return np.array([dth0, dth1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run stochastic gradient descent (SGD)\n",
    "# eta is the initial learning rate, which decays as a function of the time step\n",
    "def sgd(grad, X, y, initial_theta, eta = 0.3, max_iter = 5000, batch_size=50 ):\n",
    "    theta = initial_theta\n",
    "    thetas = [theta]\n",
    "    n = len(X)\n",
    "    for t in range(1, max_iter):\n",
    "        X_sample = X.sample(batch_size)\n",
    "        y_sample = y.loc[X_sample.index]\n",
    "        theta = theta - eta/t * grad(theta, X_sample, y_sample)\n",
    "        thetas.append(theta)\n",
    "    return thetas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = sgd(mse_gradient, X, y, \n",
    "             initial_theta = np.array([1, .5]), \n",
    "             eta = 0.001, \n",
    "             max_iter = 10000,\n",
    "             batch_size=1)\n",
    "thetas[-5:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
