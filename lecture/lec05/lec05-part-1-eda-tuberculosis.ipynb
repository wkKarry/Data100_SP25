{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f32b1ffd-6b46-41d2-91ea-58a02cd4ee31",
   "metadata": {},
   "source": [
    "# üë©‚Äç‚öïÔ∏è Lecture 5 (Part 1, Tuberculosis) ‚Äì Data 100, Spring 2025\n",
    "\n",
    "Data 100, Spring 2025\n",
    "\n",
    "[Acknowledgments Page](https://ds100.org/sp25/acks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52653181-9343-44e4-b198-540a5f3b4b28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:15.363920Z",
     "start_time": "2018-02-02T15:15:14.337886Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c76a6c48-110a-498a-918e-4269e519b83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "\n",
    "sns.set()\n",
    "sns.set_context('talk')\n",
    "np.set_printoptions(threshold=20, precision=2, suppress=True)\n",
    "pd.set_option('display.max_rows', 30)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 2)\n",
    "# Use 5 decimal places instead of scientific notation in pandas\n",
    "pd.set_option('display.float_format', '{:.5f}'.format)\n",
    "\n",
    "# Silence some spurious seaborn warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fe9f52-e4d4-4066-a56c-b5575061b979",
   "metadata": {},
   "source": [
    "# ü¶† Tuberculosis in the United States"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e1ed79-85c3-4654-bd00-f546e7fea6c0",
   "metadata": {},
   "source": [
    "What can we say about the presence of Tuberculosis in the United States?\n",
    "\n",
    "Let's work with the data included in the [original CDC article](https://www.cdc.gov/mmwr/volumes/71/wr/mm7112a1.htm?s_cid=mm7112a1_w) published in 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8867f0-f161-404d-9cd6-7c85d997d2c5",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "# üìñ Reading CSVs\n",
    "\n",
    "The TB case count data is saved as a CSV file located at `data/cdc_tuberculosis.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d1eccf-0803-4056-ac5a-ca33c0263b43",
   "metadata": {},
   "source": [
    "We can explore the CSV file in many ways:\n",
    "1. Using the JupyterLab explorer tool (read-only!).\n",
    "2. Opening the CSV in DataHub, or Excel, or Google Sheets, etc.\n",
    "3. Inspecting the Python file object\n",
    "4. With `pandas`, using `pd.read_csv()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce3c542-cd20-4689-bb0b-591d0859ebc9",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## üß≠ Methods 1 and 2: Play with the data in the JupyterLab Explorer and DataHub\n",
    " To solidify the idea of a CSV as **rectangular data** (i.e., tabular data) stored as comma-separated values, let's start with the first two methods.  \n",
    "\n",
    " **1. Use the file browser in JupyterLab to locate the CSV at `data/cdc_tuberculosis.csv`, and double-click on it.**\n",
    "\n",
    "  **2. Right-click on the CSV in the file browser. Select `Open With` --> `Editor`. But, don't make any changes to the file!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bbc449-ca93-45d7-9f07-354f9db54eb7",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## üêç Method 3: Play with the data in Python\n",
    "\n",
    "Next, we will load in the data as a Python file object and inspect a couple lines. \n",
    "\n",
    "With the code below, we can check out the first four lines of the CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf63a84-db3d-4f88-82e2-d49053d84b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the TB case count CSV, and print the first four lines\n",
    "with open(\"data/cdc_tuberculosis.csv\", \"r\") as f:\n",
    "    for i, row in enumerate(f):\n",
    "        print(row)\n",
    "        if i >= 3: break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1aa938-30b1-4929-9696-470b2dfb6c1c",
   "metadata": {},
   "source": [
    "As expected, we have four lines of comma-separated values!\n",
    "\n",
    "> Why are there blank lines between each line of the CSV file?\n",
    ">\n",
    "> You may recall that line breaks in text files are encoded with the special newline character `\\n`. \n",
    "> \n",
    "> Python's `print()` function prints each line, interpreting the `\\n` at the end of each line as a newline, **and also adds an additional newline**.\n",
    "\n",
    "We can use the `repr()` (\"representation\") function to return the raw string representation of each line (i.e., all special characters will be visible).\n",
    "\n",
    "- In other words, `print()` will not interpret `\\n` as a newline. Instead, it will literally print `\\n`.\n",
    "\n",
    "- Note, though, `print()` adds a newline each time it is called. Otherwise, we would have one long string below instead of four lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664eb6b6-b671-4314-a20f-5a99ed8ae544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the TB case count CSV, and print the raw representation of\n",
    "# the first four lines\n",
    "with open(\"data/cdc_tuberculosis.csv\", \"r\") as f:\n",
    "    for i, row in enumerate(f):\n",
    "        print(repr(row)) # print raw strings\n",
    "        if i >= 3: break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffbfc29-5c6c-4b6c-be75-9b3d549d4159",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "---\n",
    "\n",
    "## üêº Method 4: Play with the data using `pandas`\n",
    "\n",
    "It's time for the tried-and-true Data 100 approach: `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8348a64-0454-440a-ac02-c0c796aea68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_df = pd.read_csv(\"data/cdc_tuberculosis.csv\",)\n",
    "tb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1424618-8ae7-4e5e-837a-665f85a68006",
   "metadata": {},
   "source": [
    "What's going on with the \"Unnamed\" column names? \n",
    "\n",
    "And why does the first row look different than the other rows?\n",
    "\n",
    "We're ready to wrangle the data! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24610db-deef-4760-86a7-d82e4bb18693",
   "metadata": {},
   "source": [
    "A reasonable first step is to **identify the row with the right header** (i.e., the row with the column names). \n",
    "\n",
    "The `pd.read_csv()` function ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)) has a convenient `header` parameter for specifying the index of the row you want to use as the header:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9dff58-3938-4348-8fd3-b9057fde21ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# header=1 tells pandas to ignore row 0, and use row 1 as the column names\n",
    "tb_df = pd.read_csv(\"data/cdc_tuberculosis.csv\", header=1)\n",
    "tb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a30a4a",
   "metadata": {},
   "source": [
    "Notice that we no longer have \"Unnamed\" columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d89ae00-c95b-4cf7-9e1f-1cd5765b24e8",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Instructor note: Return to slides!**\n",
    "\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf49b6d-fbe0-4c6e-8ab2-b541bc72e0c1",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "# üîé Granularity of records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271b596e-15cd-43e0-9f91-86a9eab2d9f6",
   "metadata": {},
   "source": [
    "Notice that the first record (i.e., row 0) differs from the other records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9982adb2-5a77-43f4-9926-6d27617f5db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586ef544",
   "metadata": {},
   "source": [
    "Row 0 is what we call a **rollup record**, or a summary record. \n",
    "\n",
    "- The **granularity** of record 0 (i.e., the total counts summed over all states) differs from the granularity of the rest of the records (i.e., the counts for individual states).\n",
    "\n",
    "- Rollup records are often useful when displaying tables to humans. But, rollup records are generally less useful when using the data for further analysis, since the rollup record \"overlaps\" with other records (i.e., info from other rows is aggregated to create the rollup record)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25390b21-b853-4bea-8ac2-ed02a78fda99",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "Okay, EDA step two. How was the rollup record aggregated?\n",
    "\n",
    "Let's check if total TB cases (row 0) is indeed the sum of all state TB cases (all other rows). \n",
    "\n",
    "- To do this, we can drop row 0, and sum up all the remaining rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb93983-af26-4cd8-bc77-051a9d5a5bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_df.drop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04035420-d4eb-44c2-9cc7-2784eed68aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_df.drop(0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3843ad9-afe2-4787-a979-5b62e4af2c4a",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "This doesn't look very pretty!\n",
    "\n",
    "Let's check out the column types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd373432-2770-4218-af2d-4cc52d32cdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105bf5fe-4a77-4335-8fd7-6c0f8ed68ad4",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "The commas within the counts (e.g., `1,234`) cause `pd.read_csv` to read in the counts as the `object` datatype, or **storage type**. Strings are of the `object` datatype.\n",
    "\n",
    "- So, `pandas` is concatenating strings (e.g., `'1' + '2' = '12'`) instead of adding integers (e.g., `1 + 2 = 3`).\n",
    "\n",
    "<br/>\n",
    "\n",
    "Fortunately `read_csv` also has a `thousands` parameter to handle exactly this issue ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html))\n",
    "\n",
    "- Note: This is not a fact that most data scientists would know off the top of their head! At this point, it would be very natural to Google/ask an LLM `How do I get pandas to ignore commas in numeric columns?`, and then learn about the `thousands` parameter from the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539e288c-2d73-404e-8a2f-cc98d0428255",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_df = pd.read_csv(\"data/cdc_tuberculosis.csv\", header=1, thousands=',')\n",
    "tb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee99a8a",
   "metadata": {},
   "source": [
    "Notice that there are no more commas in the first row!\n",
    "\n",
    "Now, let's sum up the columns, ignoring the first row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083ccc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_df.drop(0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0c1e99",
   "metadata": {},
   "source": [
    "Much better! \n",
    "\n",
    "- Though you should note that string concatenation is still happening with the state names. To improve our code, we probably should not sum up the state name column. This exercise is left to you!\n",
    "\n",
    "Finally, let's compare this output to the first row of the original data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4e992d-39f0-48ed-9658-c63e6730199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e7f6c0-6eeb-4344-9636-00e8bc4c2c2b",
   "metadata": {},
   "source": [
    "The sums of the three TB cases columns are the same as the counts in the rollup record. Excellent!\n",
    "\n",
    "Next, we will compute TB **incidence** for each state and the U.S. as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e971e28e-460d-485f-a580-a59f4bfe8f20",
   "metadata": {},
   "source": [
    "**Instructor note: Return to the lecture!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a399666c-bae6-4d0f-ba24-139c29ab401d",
   "metadata": {},
   "source": [
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5214187a-a70d-49f9-9073-fa6e7d383482",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "# üß∫ Gather Census Data\n",
    "\n",
    "**Run the code in this section, but we won't review it during lecture.**\n",
    "\n",
    "- This section is a nice example of transforming data downloaded directly from\n",
    "a public website into a format that is convenient for analysis.\n",
    "\n",
    "The code in this section transforms CSV files with U.S. Census population estimates ([source](https://www.census.gov/data/tables/time-series/demo/popest/2010s-state-total.html) (2010s), [source](https://www.census.gov/data/tables/time-series/demo/popest/2020s-state-total.html) (2020s)) into a form that is compatible with the TB case count data.\n",
    "\n",
    "- We encourage you to explore the CSVs and study these lines outside of lecture.\n",
    "\n",
    "There are a few new methods here:\n",
    "* `df.convert_dtypes()` ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.convert_dtypes.html)) conveniently converts all float dtypes into ints and is out of scope for the class.\n",
    "* `df.drop_na()` ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html)) drops rows containing any NA value. This function will be explained in more detail in a future lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a488ed5-bb50-4005-863a-4a287fa54013",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_2010s_df = pd.read_csv(\"data/nst-est2019-01.csv\", header=3, thousands=\",\")\n",
    "\n",
    "# Notice we have more than just state data!\n",
    "display(census_2010s_df.head(10))\n",
    "\n",
    "# Also notice that the bottom of the file includes metadata (data about data).\n",
    "# We want to ignore this!\n",
    "display(census_2010s_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb51b438-045b-4d51-a043-06151995a655",
   "metadata": {},
   "source": [
    "Here we do a bit more basic data cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b52e1e-8c99-4448-ab89-cd7ad045261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_2010s_df = (\n",
    "    census_2010s_df\n",
    "    .rename(columns={\"Unnamed: 0\": \"Geographic Area\"})\n",
    "    .drop(columns=[\"Census\", \"Estimates Base\"])\n",
    "    .convert_dtypes() # \"smart\" converting of columns to int, use at your own risk\n",
    "    .dropna()  # we'll introduce this very soon\n",
    ")\n",
    "census_2010s_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a537a5a-a69e-4525-a059-5f97d38740f7",
   "metadata": {},
   "source": [
    "You might ask yourself: What is the granularity of each row in this table?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb099a8-3f86-4143-add0-7c7128b205f7",
   "metadata": {},
   "source": [
    "Notice there is a `'.'` at the beginning of all the states.  We need to remove that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccef88d4-b15c-4147-ab14-d1c511d94e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_2010s_df['Geographic Area'] = census_2010s_df['Geographic Area'].str.strip('.')\n",
    "census_2010s_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a277bf-dad5-4f59-972c-1d96810cf88e",
   "metadata": {},
   "source": [
    "The 2020s data is in a separate file.\n",
    "\n",
    "So, we will repeat the same data cleaning process on the 2020s dataset.\n",
    "\n",
    "- Even better, we could write a re-usable function to carry out the similar cleaning process for both datasets. For this demo, we will use the same code twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a20bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# census 2020s data\n",
    "census_2020s_df = pd.read_csv(\"data/NST-EST2024-POP.csv\", header=3, thousands=\",\")\n",
    "\n",
    "# Once again, we have more than just state data, and metadata at the bottom.\n",
    "# But, we also have a ton of extra blank columns!\n",
    "display(census_2020s_df.head(10))\n",
    "display(census_2020s_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368d0d13-cc1c-43a8-92c3-757ed22fc5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# census 2020s data\n",
    "census_2020s_df = (\n",
    "    census_2020s_df\n",
    "    .drop(columns=[\"Unnamed: 1\"])\n",
    "    .rename(columns={\"Unnamed: 0\": \"Geographic Area\"})\n",
    "    # ignore all the blank extra columns\n",
    "    .loc[:, \"Geographic Area\":\"2024\"]\n",
    "    .convert_dtypes()       \n",
    "    .dropna()                  \n",
    ")\n",
    "census_2020s_df['Geographic Area'] = census_2020s_df['Geographic Area'].str.strip('.')\n",
    "census_2020s_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1372d0cf",
   "metadata": {},
   "source": [
    "With that, we're in business!\n",
    "\n",
    "We now have U.S. Census data from 2019, 2020, and 2021 in a format that is compatible with our TB case count data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e4d8b6-c7f5-44d7-a2c6-e66548d65099",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "# üë• Joining TB case counts with census data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29a74f0-36fa-4a47-a0c9-2c5df6e6f9cd",
   "metadata": {},
   "source": [
    "Time to `merge` our datasets (i.e., join them)! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b901cf9-0e6d-414b-bd8d-16d2248885bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the three tables that we are going to join.\n",
    "# To keep things simple, let's just look at the last two rows of each df.\n",
    "display(tb_df.tail(2))\n",
    "display(census_2010s_df.tail(2))\n",
    "display(census_2020s_df.tail(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadc20ec",
   "metadata": {},
   "source": [
    "We're only interested in the population for the years 2019, 2020, and 2021, so let's select just those columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4e918d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the relevant population years\n",
    "census_2019_df = census_2010s_df[['Geographic Area', '2019']]\n",
    "census_2020_2021_df = census_2020s_df[['Geographic Area', '2020', '2021']]\n",
    "\n",
    "display(tb_df.tail(2))\n",
    "display(census_2019_df.tail(2))\n",
    "display(census_2020_2021_df.tail(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdac5fec",
   "metadata": {},
   "source": [
    "All three dataframes have a column containing U.S. states, along with some other geographic areas. These columns are our **join keys**.\n",
    "\n",
    "- Below, we use `df1.merge(right=df2, ...)` to carry out the merge ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html)). \n",
    "\n",
    "- We could have alternatively used the function `pd.merge(left=df1, right=df2, ...)` ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.merge.html?highlight=pandas%20merge#pandas.merge))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3e093a-860a-45f1-b976-3133f34586c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge TB dataframe with two US census dataframes\n",
    "tb_census_df = (\n",
    "    tb_df\n",
    "    .merge(right=census_2019_df,\n",
    "           left_on=\"U.S. jurisdiction\", right_on=\"Geographic Area\")\n",
    "    .merge(right=census_2020_2021_df,\n",
    "           left_on=\"U.S. jurisdiction\", right_on=\"Geographic Area\")\n",
    ")\n",
    "tb_census_df.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa22a5a3",
   "metadata": {},
   "source": [
    "To see what's going on with the duplicate columns, and the `_x` and `_y`, let's do the just the first merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296729d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_df.merge(right=census_2019_df, \n",
    "            left_on=\"U.S. jurisdiction\", \n",
    "            right_on=\"Geographic Area\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9110759b-cca6-430b-a42e-b6a23404b045",
   "metadata": {},
   "source": [
    "Notice that the columns containing the **join keys** have all been retained, and all contain the same values.\n",
    "\n",
    "- Furthermore, notice that the duplicated columns are appended with `_x` and `_y` to keep the column names unique.\n",
    "\n",
    "- In the TB case count data, column `2019` represents the number of TB cases in 2019, but in the Census data, column `2019` represents the U.S. population.\n",
    "\n",
    "We can use the `suffixes` argument to modify the `_x` and `_y` defaults to our liking ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.merge.html?highlight=pandas%20merge#pandas.merge))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944e8480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the suffixes to use for duplicated column names\n",
    "tb_df.merge(right=census_2019_df,\n",
    "           left_on=\"U.S. jurisdiction\", \n",
    "           right_on=\"Geographic Area\",\n",
    "           suffixes=('_cases', '_population')).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2d89c8",
   "metadata": {},
   "source": [
    "Notice the `_x` and `_y` have changed to `_cases` and `_population`, just like we specified.\n",
    "\n",
    "Putting it all together, and dropping the duplicated `Geographic Area` columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d926a663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redux: merge TB dataframe with two US census dataframes\n",
    "tb_census_df = (\n",
    "    tb_df\n",
    "    \n",
    "    .merge(right=census_2019_df,\n",
    "           left_on=\"U.S. jurisdiction\", right_on=\"Geographic Area\",\n",
    "           suffixes=('_cases', '_population'))\n",
    "    .drop(columns=\"Geographic Area\")\n",
    "\n",
    "    .merge(right=census_2020_2021_df,\n",
    "           left_on=\"U.S. jurisdiction\", right_on=\"Geographic Area\",\n",
    "           suffixes=('_cases', '_population'))\n",
    "    .drop(columns=\"Geographic Area\")\n",
    "    \n",
    ")\n",
    "tb_census_df.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6e25a9-11fa-4e2a-a2a5-7c4a78f29aa7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## ‚ôªÔ∏è Reproduce incidence\n",
    "\n",
    "Let's see if we can reproduce the original CDC numbers from our augmented dataset of TB case counts and state populations.\n",
    "\n",
    "- Recall that the nationwide TB incidence was **2.7 in 2019**, **2.2 in 2020**, and **2.4 in 2021**.\n",
    "\n",
    "- Along the way, we'll also compute state-level incidence.\n",
    "\n",
    "From the [CDC report](https://www.cdc.gov/mmwr/volumes/71/wr/mm7112a1.htm?s_cid=mm7112a1_w#T1_down): TB incidence is computed as ‚ÄúCases per 100,000 persons using mid-year population estimates from the U.S. Census Bureau.‚Äù\n",
    "\n",
    "Let's start with a simpler question: What is the per person incidence? \n",
    "\n",
    "- In other words, what is the probability that a randomly selected person in the population had TB within a given year?\n",
    "\n",
    "$$\\text{TB incidence per person} = \\frac{\\text{\\# TB cases in population}}{\\text{Total population size}}$$\n",
    "\n",
    "Let's calculate per person incidence for 2019:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ae1681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate per person incidence for 2019\n",
    "tb_census_df[\"per person incidence 2019\"] = (\n",
    "    tb_census_df[\"2019_cases\"]/tb_census_df[\"2019_population\"]\n",
    ")\n",
    "tb_census_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02b7906",
   "metadata": {},
   "source": [
    "TB is really rare in the United States, so per person TB incidence is really low, as expected.\n",
    "\n",
    "- But, if we were to consider 100,000 people, the probability of seeing a TB case is higher.\n",
    "\n",
    "- In fact, it would be 100,000 times higher!\n",
    "\n",
    "$$\\text{TB incidence per 100,000} = \\text{100,000} * \\text{TB incidence per person}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc21548e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To help read bigger numbers in Python, you can use _ to separate thousands,\n",
    "# akin to using commas. 100_000 is the same as writing 100000, but more readable.\n",
    "tb_census_df[\"per 100k incidence 2019\"] = (\n",
    "    100_000 * tb_census_df[\"per person incidence 2019\"] \n",
    ")\n",
    "tb_census_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1570d7",
   "metadata": {},
   "source": [
    "Now we're seeing more human-readable values.\n",
    "\n",
    "- For example, there 5.3 tuberculosis cases for every 100,000 California residents in 2019.\n",
    "\n",
    "To wrap up this exercise, let's calculate the nationwide incidence of TB in 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2723f184-e3f4-41f6-8022-1f10ce8b66cc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Recall that the CDC reported an incidence of 2.7 per 100,000 in 2019.\n",
    "tot_tb_cases_50_states = tb_census_df[\"2019_cases\"].sum()\n",
    "tot_pop_50_states = tb_census_df[\"2019_population\"].sum()\n",
    "tb_per_100k_50_states = 100_000 * tot_tb_cases_50_states / tot_pop_50_states\n",
    "tb_per_100k_50_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192936ba",
   "metadata": {},
   "source": [
    "We can use a `for` loop to compute the incidence for 2019, 2020, and 2021.\n",
    "\n",
    "- You'll notice that we get the same numbers reported by the CDC!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c1a378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f strings (f\"...\") are a handy way to pass in variables to strings.\n",
    "for year in [2019, 2020, 2021]:\n",
    "  tot_tb_cases_50_states = tb_census_df[f\"{year}_cases\"].sum()\n",
    "  tot_pop_50_states = tb_census_df[f\"{year}_population\"].sum()\n",
    "  tb_per_100k_50_states = 100_000 * tot_tb_cases_50_states / tot_pop_50_states\n",
    "  print(tb_per_100k_50_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aad5472",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "**Instructor Note: Return to Slides!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
