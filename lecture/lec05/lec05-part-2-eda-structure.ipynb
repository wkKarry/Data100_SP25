{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4875783-3a1e-47a0-bc8f-675647dfc1e1",
   "metadata": {},
   "source": [
    "# üíΩ Lecture 5 (Part 2, Data Storage Types) ‚Äì Data 100, Spring 2025\n",
    "\n",
    "Data 100, Spring 2025\n",
    "\n",
    "[Acknowledgments Page](https://ds100.org/sp25/acks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd22501d-8cb4-446f-a393-4c989ffe16cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:15.363920Z",
     "start_time": "2018-02-02T15:15:14.337886Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73babc0f-1958-4b75-9e32-f4788b5d7bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "\n",
    "sns.set()\n",
    "sns.set_context('talk')\n",
    "np.set_printoptions(threshold=20, precision=2, suppress=True)\n",
    "pd.set_option('display.max_rows', 30)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 2)\n",
    "# Use 2 decimal places instead of scientific notation in pandas\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Silence some spurious seaborn warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21a193d-131d-43af-92d3-0e189c123994",
   "metadata": {},
   "source": [
    "\n",
    "<br><br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## ü§π‚Äç‚ôÄÔ∏è File Formats Other than CSV\n",
    "\n",
    "There are many file types for storing structured data: CSV, TSV, JSON, XML, ASCII, SAS...\n",
    "* In lecture, we will cover TSV and JSON since `pandas` supports them out-of-box."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98960f5a-f880-447b-ad8b-629ad06061b4",
   "metadata": {},
   "source": [
    "TSV stands for tab-separated values. Think CSV, but with tabs (`\\t`) as the delimeter instead of commas.\n",
    "\n",
    "- TSVs are [technically faster](https://stackoverflow.com/questions/11130120/choosing-between-tsv-and-csv) to import than CSVs. \n",
    "\n",
    "- But, historical tradition has led to CSV being the more popular file format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e768a4b",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Like we did with `data/cdc_tuberculosis.csv`, you can open `data/cdc_tuberculosis.tsv` in the JupyterLab Explorer to see its contents.\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21184855",
   "metadata": {},
   "source": [
    "The `pd.read_csv` function also reads TSVs if we specify the **delimiter** with parameter `sep='\\t'` ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd4a443-a27a-4845-8fd9-f99fad26784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identical data to Part 1!\n",
    "tuberculosis_df_tsv = pd.read_csv(\"data/cdc_tuberculosis.tsv\", sep='\\t')\n",
    "tuberculosis_df_tsv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb3e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV representation\n",
    "with open(\"data/cdc_tuberculosis.csv\", \"r\") as f:\n",
    "    for _, row in zip(range(4), f):\n",
    "        print(row) # print raw strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bcc7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSV representation\n",
    "with open(\"data/cdc_tuberculosis.tsv\", \"r\") as f:\n",
    "    for _, row in zip(range(4), f):\n",
    "        print(row) # print raw strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fa20d2-0cbe-4da7-a3db-dae144a3ecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print literal \\t instead of tabbed spaces:\n",
    "with open(\"data/cdc_tuberculosis.tsv\", \"r\") as f:\n",
    "    for _, row in zip(range(4), f):\n",
    "        print(repr(row)) # print raw strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d419f25-32c1-4b61-aa05-0c471e01a6cf",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "**Instructor note: Return to Slides!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b4697e-8dad-452d-b956-a2687850f655",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br> <br>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### ü™Ü JSON (JavaScript Object Notation)\n",
    "\n",
    "The [congress.gov API](https://gpo.congress.gov/#/) (Application Programming Interface) provides data about the activities and members of the United States Congress (i.e., the House of Representatives and the Senate).\n",
    "\n",
    "- Click the link above to see the kinds of information provided by the API. \n",
    "\n",
    "<br>\n",
    "\n",
    "To get a JSON file containing information about the current members of Congress from California, you could use the following **API call**:\n",
    "\n",
    "- `https://api.congress.gov/v3/member/CA?api_key=[INSERT_KEY]&limit=250&format=json&currentMember=True`\n",
    "\n",
    "- You can instantly sign up for a congress.gov **API key** [here](https://gpo.congress.gov/sign-up/). Once you have your key, replace `[INSERT_KEY]` above with your key, and enter the API call as a URL in your browser. What happens? \n",
    "\n",
    "- Once the JSON from the API call is visible in your browser, you can click `File` --> `Save Page As` to save the JSON file to your coputer.\n",
    "\n",
    "- Coarsely, API keys are used to track how much a given user engages with the API. There might be limits to the number of API calls (e.g., congress.gov API limits to 5,000 calls per hour), or a cost for API calls (e.g., using the OpenAI API for programmatically using ChatGPT).\n",
    "\n",
    "<br>\n",
    "\n",
    "For convenience, the JSON file from the call above has already been downloaded for you and is saved at `data/ca-congress-members.json`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1552740-b687-4252-93b5-fe7c31cc9080",
   "metadata": {},
   "source": [
    "#### üìÅ File contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f5a198",
   "metadata": {},
   "source": [
    "Let's look at `data/ca-congress-members.json` in the JupyterLab Explorer.\n",
    "\n",
    "- Right-click the file, and then click `Open With` --> `Editor`.\n",
    "\n",
    "- You'll notice that JSON looks a lot like a Python dictionary.\n",
    "\n",
    "- Berkeley, CA is in the 12th district. Can you find our representative in Congress?\n",
    "\n",
    "> Note: In general, it's a good idea to check the file size before opening a file in JupyterLab. Very large files can cause crashes. See `os.path.getsize` [documentation](https://docs.python.org/3/library/os.path.html#os.path.getsize)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c5d61d",
   "metadata": {},
   "source": [
    "We can programmatically view the first couple lines of the file using the same functions we used with CSVs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bc5b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_file = \"data/ca-congress-members.json\"\n",
    "\n",
    "# Inspect the first five lines of the file\n",
    "with open(congress_file, \"r\") as f:\n",
    "    for i, row in enumerate(f):\n",
    "        print(row)\n",
    "        if i >= 4: break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fa0b37-70b7-4eaa-be61-73632928eecb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### üêç EDA: Digging into JSON with Python\n",
    "\n",
    "JSON data closely matches the internal Python object model.  \n",
    "\n",
    "- In the following cell, we import the entire JSON datafile into a Python dictionary using the `json` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e227500a-c56b-41c4-bbe8-60ee0f2ce088",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:19.441300Z",
     "start_time": "2018-02-02T15:15:19.358900Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Import the JSON file into Python as a dictionary\n",
    "with open(congress_file, \"rb\") as f:\n",
    "    congress_json = json.load(f)\n",
    "\n",
    "type(congress_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27745131-6d69-485a-adcf-928032b0f425",
   "metadata": {},
   "source": [
    "The `congress_json` variable is a dictionary encoding the data in the JSON file.\n",
    "\n",
    "Below, we access the first element of the `members` element of the `congress_json` dictionary.\n",
    "\n",
    "- This first element is also a dictionary (and there are more dictionaries inside of it!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309f570e-8803-40ab-821d-1e654713d89a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:19.447238Z",
     "start_time": "2018-02-02T15:15:19.443595Z"
    }
   },
   "outputs": [],
   "source": [
    "# Grab the list corresponding to the `members` key in the JSON dictionary, \n",
    "# and then grab the first element of this list.\n",
    "# In a moment, we'll see how we knew to use the key `members`, and that\n",
    "# the resulting object is a list.\n",
    "congress_json['members'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe0fb62",
   "metadata": {},
   "source": [
    "How should we probe a nested dictionary like `congress_json`?\n",
    "\n",
    "We can start by identifying the top-level **keys** of the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d9e1bb-6c88-46d4-9348-29aaa71596b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:19.680999Z",
     "start_time": "2018-02-02T15:15:19.675696Z"
    }
   },
   "outputs": [],
   "source": [
    "# Grab the top-level keys of the JSON dictionary\n",
    "congress_json.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29129c86-329d-4fbd-b597-07636d059a12",
   "metadata": {},
   "source": [
    "Looks like we have three top-level keys: `members`, `pagination`, and `request`.\n",
    "\n",
    "> You'll often see a top-level `meta` key in JSON files. This does not refer to Meta (formerly Facebook). Instead, it typically refers to metadata (data about the data).  Metadata are often maintained alongside the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f4e8a4",
   "metadata": {},
   "source": [
    "Let's check the type of the `members` element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81df92a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(congress_json['members'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b79e9eb",
   "metadata": {},
   "source": [
    "Looks like a list! What are the first two elements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0779748d",
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_json['members'][:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941d7b4b",
   "metadata": {},
   "source": [
    "More dictionaries! You can repeat the process above to traverse the nested dictionary.\n",
    "\n",
    "You'll notice that each record of `congress_json['members']` looks like it could be a column of a DataFrame.\n",
    "\n",
    "- The keys look a lot like column names, and the values could be the entries in each row.\n",
    "\n",
    "<br> \n",
    "\n",
    "But, the two other elements of `congress_json` don't have the same structure as `congress_json['members']`.\n",
    "\n",
    "- So, they probably don't belong in a DataFrame containing the members of Congress from CA.\n",
    "\n",
    "- We'll see the implications of this inconsistency in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542ffc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(congress_json['pagination'])\n",
    "print(congress_json['request'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89da4483-77d0-40e1-8a68-8c3367f6ef09",
   "metadata": {},
   "source": [
    "### üêº JSON with pandas\n",
    "\n",
    "`pandas` has a built in function called `pd.read_json` for reading in JSON files. \n",
    "\n",
    "- Uncomment the code below and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "889e7992-1e89-4df7-ba44-1da412e5aa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_json(congress_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e665fba",
   "metadata": {},
   "source": [
    "Uh oh. Using the default parameters, we got an error. \n",
    "\n",
    "- The code above tries to import the entire JSON file located at `congress_file` (`congress_json`), including `congress_json['pagination']` and `congress_json['request']`.\n",
    "\n",
    "- We only want to make a DataFrame out of `congress_json['members']`.\n",
    "\n",
    "This time, let's try converting the `members` element of `congress_json` to a DataFrame by using `pd.DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61dffb3-4d0c-4e72-8b2c-dac07bdf044e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:19.793306Z",
     "start_time": "2018-02-02T15:15:19.725044Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert dictionary to DataFrame\n",
    "congress_df = pd.DataFrame(congress_json['members'])\n",
    "congress_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d035283",
   "metadata": {},
   "source": [
    "We've successfully begun to rectangularize our JSON data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6300e4-fb50-442b-a6a6-472f1ba40001",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "**Instructor Note: Return to Slides!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c337f37b-8661-4ec5-a00a-c953adf86be6",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## üï∞Ô∏è Temporality\n",
    "\n",
    "Let's briefly look at how we can use pandas `dt` accessors to work with dates/times in a dataset.\n",
    "\n",
    "We will use the Berkeley Police Department (PD) Calls for Service dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdb38de-c276-41c6-8b5a-97d2a1798961",
   "metadata": {},
   "outputs": [],
   "source": [
    "calls = pd.read_csv(\"data/Berkeley_PD_-_Calls_for_Service.csv\")\n",
    "calls.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d5d1af-5520-410c-9d36-182de0f5edaf",
   "metadata": {},
   "source": [
    "Looks like there are three columns with dates/times: `EVENTDT`, `EVENTTM`, and `InDbDate`. \n",
    "\n",
    "- `EVENTDT` stands for the **date** when the event took place\n",
    "\n",
    "- `EVENTTM` stands for the **time of day** the event took place (in 24-hr format)\n",
    "\n",
    "- `InDbDate` is the date this call is entered into the database.\n",
    "\n",
    "We can convert these string columns to `datetime` objects using the `pd.to_datetime` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d11c08-b507-4158-ad2c-2b644516d073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.to_datetime() is smart -- It can often infer what you want based on\n",
    "# the format of the datetime string.\n",
    "# But, it's not always right! It's good practice to specify the format of \n",
    "# your datetimes. See the documentation and the `format` argument.\n",
    "\n",
    "# Without format specified:\n",
    "calls[\"EVENTDT\"] = pd.to_datetime(calls[\"EVENTDT\"])\n",
    "\n",
    "# With format specified:\n",
    "# calls[\"EVENTDT\"] = pd.to_datetime(calls[\"EVENTDT\"], format='%m/%d/%Y %I:%M:%S %p')\n",
    "\n",
    "calls.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2261c47d-22ec-4709-a9e2-129b481ec0bf",
   "metadata": {},
   "source": [
    "Now we can use the `dt` accessor on this column.\n",
    "\n",
    "We can get the month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b4df05-b134-41cc-8095-9122330ff42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - January, 2 - February, ..., 12 - December\n",
    "calls[\"EVENTDT\"].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58102f15-0e7e-46b5-aaa9-f9bf65cbfbed",
   "metadata": {},
   "source": [
    "Which day of the week the date is on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934245aa-b0c0-40f7-8a44-843e5a342602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 - Monday, 1 - Tuesday, ..., 6 - Sunday\n",
    "calls[\"EVENTDT\"].dt.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a4630a-7fe3-4998-90f9-304e187a5cff",
   "metadata": {},
   "source": [
    "We can also sort by datetime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff0750f-87d3-491c-a417-5c208527ae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by datetime to find the earliest call.\n",
    "calls.sort_values(\"EVENTDT\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf089df9-ceef-44d8-a397-fa3d8b119cfe",
   "metadata": {},
   "source": [
    "We can also do many things with the `dt` accessor like switching time zones and converting time back to UNIX/POSIX time. Check out the documentation on [`.dt` accessor](https://pandas.pydata.org/docs/user_guide/basics.html#basics-dt-accessors) and [time series/date functionality](https://pandas.pydata.org/docs/user_guide/timeseries.html#)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a8ae03",
   "metadata": {},
   "source": [
    "What type are datetime objects?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0871343",
   "metadata": {},
   "outputs": [],
   "source": [
    "calls[\"EVENTDT\"].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1e37a9",
   "metadata": {},
   "source": [
    "`ns` above stands for nanoseconds.\n",
    "\n",
    "- `<M8` refers to the Numpy type `datetime64`\n",
    "\n",
    "Under the hood, datetimes in Pandas are integers representing the number of **nanoseconds** since 1/1/1970 UTC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa4c16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetimes in pandas are stored as integers representing number of \n",
    "# nanoseconds since 1970-01-01\n",
    "calls[\"EVENTDT\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9237b2e5",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "**Instructor Note: Return to Slides!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22c4343",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## ü§∑ Faithfulness and missing values\n",
    "\n",
    "To conclude, let's **very** briefly explore missingness in the Berkeley PD Calls for Service dataset.\n",
    "\n",
    "Looking at the top of the dataframe, we can already see that there are missing values in the `BLKADDR` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc64a710",
   "metadata": {},
   "outputs": [],
   "source": [
    "calls.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7732de36",
   "metadata": {},
   "source": [
    "We can use the `.isna()` method to get a sense of how often values in `BLKADDR` are missing.\n",
    "\n",
    "- The `.isnull()` method is functionally equivalent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8cd271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isna() returns a Series of booleans indicating whether each element \n",
    "# # in the Series is missing.\n",
    "print(calls['BLKADDR'].isna().head())\n",
    "\n",
    "# The mean of a Series of booleans is the proportion of booleans that are True.\n",
    "calls['BLKADDR'].isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6047c157",
   "metadata": {},
   "source": [
    "It looks like missing values are actually quite rare: Only 0.8% of records are missing a value in `BLKADDR`.\n",
    "\n",
    "Why are these values missing? \n",
    "\n",
    "- Again, looking at just the first few rows, we see that `NaN` values in `BLKADDR` appear to be accompanied by latitude/longitude coordinates in the `Block_Location` column.\n",
    "\n",
    "- In all likelihood, missing values in `BLKADDR` probably correspond to locations that do not have a defined address in the officer's navigation or GPS system.\n",
    "\n",
    "<br>\n",
    "\n",
    "The best default approach here: Leave the rows with missing `BLKADDR` untouched, or replace the `NaN` values with a `MISSING` indicator.\n",
    "\n",
    "- In the future, if we wanted to conduct an analysis of the streets where police incidents were most common, we might impute `BLKADDR` by using the nearest street, which we could identify with an external package.\n",
    "\n",
    "<br>\n",
    "\n",
    "For a very rough sense of missingness in each column of a DataFrame, you can use the `info()` method.\n",
    "\n",
    "- Based on the output, it looks like the only column with missing values is `BLKADDR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56104490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can see the total number of rows at the top of the .info() output.\n",
    "# Compare this to the number of non-null values in the BLKADDR column.\n",
    "calls.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0c9d5d",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "**Instructor Note: Return to Slides!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
